{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q -1 Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"4a1da16d-cb58-4e7c-a5ef-3e7aded4e124\")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the web element of the search block\n",
    "search_job=driver.find_element_by_xpath(\"//input[@id='qsb-keyword-sugg']\")\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering data analyst in  search \n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"8f532a4c-e003-456a-95b6-5c30d93dd937\")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the web element of the location block\n",
    "search_location=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering bangalore in  search \n",
    "search_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"2710b00e-51e1-4456-9e71-1056412bb092\")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#web element of search \n",
    "search=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to click on search \n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"5077ec3d-558d-48ec-bf90-2f5367bd78f4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"0d7fbc53-46eb-443e-b9e6-cf75833547ca\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"0fe4fb2a-218f-45f3-a56f-60207897b80c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"ab625a83-e0bc-4a54-996d-f54b6790cc1c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"34a373ca-d328-4e57-89d9-9a88f9939224\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"336871a9-d2b8-4b2f-9cdd-364d72b182a4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"550ae6fa-db3c-495e-88ff-988fae3c1f24\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"0b918334-64a9-4516-a048-e7f4f1093a37\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"377e4c35-d373-4891-885d-216b22929788\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"ce7f70c0-924d-48ab-bd28-4a4ff7c806b4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"03e2fbf9-7757-470c-aa78-d5eb2b27c3d9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"e2c632aa-8f05-47f0-b62a-c7aacfe73f1c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"db98d029-0387-41e8-93d9-d2dee22dd661\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"ea5fc0f9-af7e-4227-ba6a-f6f10bd06038\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"d6ea0181-4021-41ff-9635-579f2c4eb268\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"616da687-1f94-4a74-af53-140fb6187c2d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"26455981-b119-4de3-9546-3e13eed96b78\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"84df5375-e02c-434b-b565-17798ebfe426\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"8aa4c4ca-fabe-4270-bf50-4b0e4a4cc39e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"8fc76faa-ae1c-486e-979a-db278b9021e4\")>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst IDAM Services',\n",
       " 'Data Analyst/Sr.Data Engineer',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst - Google Data Studio & SQL',\n",
       " 'Executive Data Analyst',\n",
       " 'Data Analyst - I/II',\n",
       " 'Data Analyst',\n",
       " 'Hiring For the role - DATA Analyst (Flipkart)',\n",
       " 'Hiring For the role - DATA Analyst (Flipkart)',\n",
       " 'Senior Associate, Data Hierarchy Analyst( MDM)',\n",
       " 'Business Data Analyst - MIS & Reporting',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - Python/SQL',\n",
       " 'Data Analyst - EdTech',\n",
       " 'Lead , Data Analyst',\n",
       " 'Product Data Analyst',\n",
       " 'Data Analyst/Sr.Analyst - Bangalore',\n",
       " 'SENIOR MARKETING DATA ANALYST']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping job title\n",
    "Title=[]\n",
    "for i in job_title:\n",
    "    Title.append(i.text)\n",
    "Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"27cb1669-48e2-4b8a-ac05-36a02fecf08e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"b7d67272-a334-4053-bbd8-75166ed0472f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"cf2f55d1-9450-47b3-b152-c3a49f9ec7ab\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"816d4bf2-18d9-4bd2-bf68-ba409420f9aa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"f82d726b-bbce-4474-a484-822ec96d9fa2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"b20d29c5-76c6-405f-9882-8cd07576837d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"6912d9eb-da3b-426e-9616-202773a76511\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"ccc5b98a-9e6b-435e-8137-01af1008aa11\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"136d92c5-e123-467e-b8ec-132e9b5a075d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"8449be86-4b05-449b-a458-883dba2a787e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"59275c07-74e9-4b35-a425-dfcab9c8bb78\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"178739a8-bc74-41d6-a1ee-241cf68599c4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"9ec5c4de-7438-4e5c-896f-4756906291c5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"91704021-0a96-44fb-943f-e1b34949b6cb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"fdf6b204-098f-4702-adc2-45ada0d97095\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"b3694af8-ad22-4bfc-8c45-3f4448a8e410\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"bd6276be-1c11-4092-9ad5-359c210e6861\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"61dba841-d250-49a1-bb0e-468f00832bd9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"40659a8b-f7a6-4ee4-9e1b-f93a2b6b6e17\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"5cf31119-75ab-4adb-a3aa-7fe0827cbd5e\")>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-8 Yrs',\n",
       " '4-9 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-8 Yrs',\n",
       " '0-3 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-4 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-3 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-3 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-5 Yrs',\n",
       " '2-6 Yrs',\n",
       " '6-11 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping experience for each job title \n",
    "Experience =[]\n",
    "for i in ex:\n",
    "    Experience.append(i.text)\n",
    "Experience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"80b4e556-a501-4b8c-a35e-71a1f415f614\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"3b88e241-a7c3-45a1-9e96-0dcce9d09eb2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"689e505f-5d2e-4157-873d-1c2f77ab4fa6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"1eae5fab-3d6c-45f1-b722-6da380cef437\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"a04e017b-6a58-44ae-987e-8a47448166d3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"206aee8b-b249-4bea-b12e-36c1f04885db\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"b250b55d-e2ff-4829-8554-5296dd5c59f1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"e6c2b077-fca5-4c69-8bed-72458c23aa47\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"890e8b19-fd89-492c-8716-f85b7c1f52a0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"31d1985b-e340-4b4a-8174-6600e7724c62\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"c7246ec9-d483-4abf-b6fb-14e80bc9880f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"64a55a12-850c-4ec0-abcf-c5a51d5060a8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"2635cfb9-e3cb-4f50-b680-20d9a7020f32\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"ba0563f9-374b-49da-b30d-76e728126570\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"62726b65-bd2f-4df1-a407-1d9c07d2404e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"0ad28fb0-d749-428a-af83-07ce98a0bfb4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"d57ef309-6fba-4740-9fa1-afa3ca6b4195\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"68bcd219-3c92-4871-993c-b59e46d301ac\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"c6b3899d-c8dc-4900-b356-4ddbc05b0f55\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"244afa5bb2edf248e68570a56f8b1658\", element=\"8ffdef21-74c4-41c9-9537-c3fd17ed1618\")>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'SYREN TECHNOLOGIES PRIVATE LIMITED',\n",
       " 'Trigent Software',\n",
       " 'Trigent Software',\n",
       " 'AVE-Promagne',\n",
       " 'Gokaldas Exports Ltd',\n",
       " 'Philips India Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'GENPACT India Private Limited',\n",
       " 'INTERTRUST GROUP',\n",
       " 'Flipkart',\n",
       " 'Flipkart',\n",
       " 'Affine',\n",
       " 'TalentStack',\n",
       " 'Near Pte. Ltd.',\n",
       " 'Trifacta',\n",
       " 'Cocentrus',\n",
       " 'McAfee Software (India) Pvt. Ltd']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping company name \n",
    "Company=[]\n",
    "for i in com:\n",
    "    Company.append(i.text)\n",
    "Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru(Bellandur)\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru(Bellandur)\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "Location=[]\n",
    "for i in location:\n",
    "    Location.append(i.text)\n",
    "Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-senior-data-analyst-idam-services-glaxosmithkline-pharmaceuticals-limited-bangalore-bengaluru-4-to-8-years-080921501391?src=jobsearchDesk&sid=16311353550739777&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-analyst-sr-data-engineer-syren-technologies-private-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-4-to-9-years-080921005341?src=jobsearchDesk&sid=16311353550739777&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-business-data-analyst-trigent-software-private-limited-bangalore-bengaluru-5-to-10-years-080921602383?src=jobsearchDesk&sid=16311353550739777&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-business-data-analyst-trigent-software-private-limited-bangalore-bengaluru-5-to-10-years-080921002381?src=jobsearchDesk&sid=16311353550739777&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-business-data-analyst-google-data-studio-sql-ave-promagne-bangalore-bengaluru-3-to-8-years-070921902812?src=jobsearchDesk&sid=16311353550739777&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-executive-data-analyst-gokaldas-exports-ltd-bangalore-bengaluru-0-to-3-years-030921004749?src=jobsearchDesk&sid=16311353550739777&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-analyst-i-ii-philips-india-limited-bangalore-bengaluru-3-to-6-years-060921501992?src=jobsearchDesk&sid=16311353550739777&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-analyst-ibm-india-pvt-limited-bengaluru-bangalore-1-to-4-years-070921901682?src=jobsearchDesk&sid=16311353550739777&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-the-role-data-analyst-flipkart-allegis-services-india-pvt-ltd-bangalore-bengaluru-1-to-6-years-060921609724?src=jobsearchDesk&sid=16311353550739777&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-the-role-data-analyst-flipkart-allegis-services-india-pvt-ltd-bangalore-bengaluru-1-to-6-years-060921009722?src=jobsearchDesk&sid=16311353550739777&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-associate-data-hierarchy-analyst-mdm-genpact-india-private-limited-bangalore-bengaluru-1-to-3-years-180821005554?src=jobsearchDesk&sid=16311353550739777&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-business-data-analyst-mis-reporting-intertrust-group-mumbai-bangalore-bengaluru-3-to-8-years-270121001879?src=jobsearchDesk&sid=16311353550739777&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-analyst-flipkart-bangalore-bengaluru-2-to-3-years-010921906563?src=jobsearchDesk&sid=16311353550739777&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-analyst-flipkart-bangalore-bengaluru-3-to-8-years-010921905921?src=jobsearchDesk&sid=16311353550739777&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-analyst-python-sql-affine-bangalore-bengaluru-3-to-5-years-080921903676?src=jobsearchDesk&sid=16311353550739777&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-analyst-edtech-talentstack-bangalore-bengaluru-2-to-6-years-080921904427?src=jobsearchDesk&sid=16311353550739777&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-analyst-near-pte-ltd-bangalore-bengaluru-6-to-11-years-070921500160?src=jobsearchDesk&sid=16311353550739777&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-product-data-analyst-trifacta-bangalore-bengaluru-2-to-5-years-060921501663?src=jobsearchDesk&sid=16311353550739777&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-analyst-sr-analyst-bangalore-cocentrus-bangalore-bengaluru-5-to-10-years-060921905500?src=jobsearchDesk&sid=16311353550739777&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-marketing-data-analyst-mcafee-software-india-pvt-ltd-bangalore-bengaluru-3-to-7-years-010921500299?src=jobsearchDesk&sid=16311353550739777&xp=20&px=1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting urls from each job listed \n",
    "job_url=[]\n",
    "for i in job_title:\n",
    "    job_url.append(i.get_attribute(\"href\"))\n",
    "job_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job description\\n  Identity and Access Management is a function within the Tech Ops group that globally manages directories, accounts, access, passwords, federation and sign-on functions. It provides a secure foundation, with standard process and tools to ensure access to GSK information and systems is protected.\\nTo work with designated TECH groups to identify opportunities to improve internal performance by optimizing processes, facilitating change and exploiting information technology to meet Identity Access Management (IAM) objectives. To provide business consulting and analysis expertise in the development of TECH strategies.\\nTo perform business analysis activities to define IAM needs, develop the benefits case for change or process improvement projects, define requirements, develop project charters and ensure benefit is delivered. To take an active role in the management of data in IDAM systems to facilitate its use by the business.\\nThis role will provide YOU the opportunity to lead key activities to progress YOUR career. These responsibilities include some of the following:\\nAssist with the development of TECH strategies for IAM. Perform analysis during design, development and implementation of change and process redesign, working with Project Managers, Act both as a technical Lead and/or architect to ensure that requirements are met and benefits realised for TECH projects.\\nRepresent TECH on management teams, cross-functional teams, and committees. Use analytical techniques and tools to improve IAM performance or solve problems by optimizing processes, facilitating change, improving compliance with existing processes, and applying information technologies.\\nFacilitate communications between Business Partners and TECH. Identify interdependency of changes in IAM processes and TECH systems. Partner with TECH colleagues to optimize the IAM TECH product portfolio\\nTechnical support for the new/other team members - share knowledge, best practices, procedures and processes\\nContribute towards the management of TECH aspects of business initiatives (such as audits, MAADs, TSR Security Response etc.) and assist IDAM in managing changes\\nOwn the technical BI architecture strategy that will increase customer value and adoption of well-architected cloud solutions across Hosting.\\nIn partnership with 3rd party tech suppliers formulate and execute delivery of a customer-focused BI architecture.\\nStrong experience in Power BI, ServiceNow, SQL, Azure ADF, IDAM process,\\nReview project team architectural designs to ensure consistency alignment with defined target architecture and adherence to established standards\\nProvide BI solution designs to meet business requirements; collaborating with Tech Enterprise Architecture (EA) for approval to ensure alignment to best practices and architectural principles and practices.\\nDevelop ETL/ELT processes, data lakes, data warehouse databases, cubes, reports, dashboards, in-line with reporting strategy and architecture. Assist in developing standards for data lakes, data ingestion, data access layers and BI solutions as key components of the BI architecture. Building Single Source of Truth Data lakes using Azure ADF, Rest API and build the BI solutions on top of it.\\nDesign models and databases both relational and dimensional and analytics cubes to support reporting requirements. Guide and prioritise the development of BI whitepapers, data sheets, and other high-value customer facing guidance and best practices.\\nDevelop and maintain understanding of:\\n- Knowledge of IDAM processes, systems and objectives;\\n- Industry-wide practices and trends in TECH solutions for IAM;\\n-Mainstream development methodologies, analysis techniques, target policy guidelines and standards\\nRoleSenior Outside Consultant\\nIndustry TypePharmaceutical & Life Sciences\\nFunctional AreaStrategy, Management Consulting, Corporate Planning\\nEmployment TypeFull Time, Permanent\\nRole CategoryCorporate Planning/Consulting/Strategy\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nProcurementBusiness analysisAccess managementActive directoryAgileHealthcareInformation technologyTechnical supportAnalyticsSQL',\n",
       " 'Job description\\nResponsibilities:\\nProvide innovative analytical insights within the Data\\nConduct detailed data analysis on data used across business units to evaluate business processes and improve on/create new feature\\nRespond to data and product related inquiries in real-time to support business and technical teams\\nPerform various data analytics in SQL and MS Excel using statistical models or industry accepted tools\\nProvide relational database expertise to construct and execute SQL queries to be used in data analysis activities\\nProvide data solutions, tools, and capabilities to enable self-service frameworks for data consumers\\nProvide expertise and translate the business needs to design; and develop tools, techniques, and metrics, and dashboards for insights and data visualization\\nResponsible for developing and executing tools to monitor and report on data quality\\nResponsible for establishing appreciation and adherence to the principles of data quality management, including metadata, lineage, and business definitions\\n\\nRequirements.\\nDegree in computer science or equivalent preferred.\\nMust have 5-8 years of total IT experience on Microsoft Power BI, SQL Server, SSIS, SSRS, SSAS.\\nDebugging and Troubleshooting SSIS Packages.\\nImplemented Error Handling/ debugging the packages with Data Viewers, break points, Event Handlers and Configure Error Output.\\nStrong Knowledge in SQL Server BI suite (SSIS, SSAS, SSRS Reporting, Analytics, and Dashboards).\\nStrong Knowledge in ETL Design, Development, Implementation and Support using SQL Database, data warehousing environments.\\nExperience in creating T-SQL Procedures, Functions and Indexes based on business requirements.\\nExpert in Data Extraction, Transforming and Loading (ETL) using SSIS.\\nDesigning and developing the SSIS Packages.\\nExperience Developing visual reports, dashboards and cards using Power BI desktop.\\nExperience in Connecting to data sources, importing data, and transforming data for Business Intelligence.\\n\\nPerks and Benefits\\n\\nAn Opportunity to work with fortune 50 clients\\nSalary best in the industry + Performance Bonus.\\n\\nImmediate joiners will be given more priority less than 30 days notice\\nRoleDatabase Architect/Designer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nKey Skills\\nBusiness IntelligenceMicrosoft Power BiBiData ModelingData AnalyticsETL ToolSSISSQL',\n",
       " 'Job description\\nDear Candidates\\n\\nWe have a Immediate requirement of Business Data Analyst for one of our Client at Bangalore Location.\\n\\nSummary\\nLocation: Bangalore\\nExperience: 5+  years experience level is required.\\nPosition:  Business Data Analyst\\nImmediate joiners preferred within 15 days joiners acceptable.\\n\\nJD for Business Data Analyst:\\n\\nJob Summary\\n\\nDevelop, maintain, and take ownership of key Business Metrics and Dashboards by engaging with stakeholders.\\nAutomate existing Reports and Dashboards using Power Automate, Power Query, VBA and Develop data models using Visual Studio.\\nPerform ETL/ELT operations and write automation/job scripts using Python/Shell.\\nConfigure and manage data sources- Oracle, MS SQL Server, MySQL.\\nDevelop and deploy cloud data models on Azure/AWS/Google Cloud\\nCreate Continuous Integration and Deployment pipelines of reports and Dashboards\\nSupport and work alongside a cross-functional team on the latest technologies\\n\\nJob Requirements\\n\\nHands-on experience with Tableau Development\\nData Cleaning, Massaging, Writing Complex calculations\\n\\n-DB tools: Oracle, MS SQL server\\n\\n-R and/or Python with be an advantage.\\n\\n-Experience in Power BI would be a plus.\\n\\nExperience with open-source technologies and cloud services like Azure Analysis Services.\\nExperience in Machine Learning is a plus\\nCommand over advanced MS Excel, DAX Formulas, Power Point\\nExcellent critical thinking skills with Strong attention to details\\nSelf starter and Self Propelled who can work with minimum management instruction\\nExcellent Business analysis and analytical skills\\nTeam player with ability to engage with multiple stakeholders in different time-zones\\nExcellent communication skills\\nExperience with engaging with Senior Management\\nSCM/Operations domain knowledge as well as experience with Tools like Anaplan would be an added advantage\\n\\nEducation\\n\\nBachelors Degree or Masters in Computer Science, Engineering, Data Science, or a relevant field.\\n\\nTotal relevant experience: 5 Plus years\\n\\nRegards\\nNaveen Kumar N\\nMail id: naveen_k@trigent.com\\nContact no: 9108228912 (Call between 9:30 Am to 6:30 Pm on Weekdays only)\\nRoleBusiness Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategorySystem Design/Implementation/ERP/CRM\\nEducation\\nUG :Any Graduate\\nKey Skills\\nDAX Formulascloud servicespythonMS ExcelBusiness Data AnalystPower Pointopen-source technologiesTableauELTMachine LearningTableau DevelopmentMassagingAzure AnalysisData Analysisshell scriptingData CleaningOracleETLMS SQL server',\n",
       " 'Job description\\nDear Candidates\\n\\nWe have a Immediate requirement of Business Data Analyst for one of our Client at Bangalore Location.\\n\\nSummary\\nLocation: Bangalore\\nExperience: 5+  years experience level is required.\\nPosition:  Business Data Analyst\\nImmediate joiners preferred within 15 days joiners acceptable.\\n\\nJD for Business Data Analyst:\\n\\nJob Summary\\n\\nDevelop, maintain, and take ownership of key Business Metrics and Dashboards by engaging with stakeholders.\\nAutomate existing Reports and Dashboards using Power Automate, Power Query, VBA and Develop data models using Visual Studio.\\nPerform ETL/ELT operations and write automation/job scripts using Python/Shell.\\nConfigure and manage data sources- Oracle, MS SQL Server, MySQL.\\nDevelop and deploy cloud data models on Azure/AWS/Google Cloud\\nCreate Continuous Integration and Deployment pipelines of reports and Dashboards\\nSupport and work alongside a cross-functional team on the latest technologies\\n\\nJob Requirements\\n\\nHands-on experience with Tableau Development\\nData Cleaning, Massaging, Writing Complex calculations\\n\\n-DB tools: Oracle, MS SQL server\\n\\n-R and/or Python with be an advantage.\\n\\n-Experience in Power BI would be a plus.\\n\\nExperience with open-source technologies and cloud services like Azure Analysis Services.\\nExperience in Machine Learning is a plus\\nCommand over advanced MS Excel, DAX Formulas, Power Point\\nExcellent critical thinking skills with Strong attention to details\\nSelf starter and Self Propelled who can work with minimum management instruction\\nExcellent Business analysis and analytical skills\\nTeam player with ability to engage with multiple stakeholders in different time-zones\\nExcellent communication skills\\nExperience with engaging with Senior Management\\nSCM/Operations domain knowledge as well as experience with Tools like Anaplan would be an added advantage\\n\\nEducation\\n\\nBachelors Degree or Masters in Computer Science, Engineering, Data Science, or a relevant field.\\n\\nTotal relevant experience: 5 Plus years\\n\\nRegards\\nNaveen Kumar N\\nMail id: naveen_k@trigent.com\\nContact no: 9108228912 (Call between 9:30 Am to 6:30 Pm on Weekdays only)\\nRoleBusiness Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategorySystem Design/Implementation/ERP/CRM\\nEducation\\nUG :Any Graduate\\nKey Skills\\nDAX Formulascloud servicespythonMS ExcelBusiness Data AnalystPower Pointopen-source technologiesTableauELTMachine LearningTableau DevelopmentMassagingAzure AnalysisData Analysisshell scriptingData CleaningOracleETLMS SQL server',\n",
       " 'Job description\\nYour responsibilities will include but not limited to:\\n\\nBuilding interactive dashboards and visualizations on Tableau and/or Google Data Studio platform\\nProviding data analysis, reporting, and data support to internal and external stakeholders to drive business process improvements and achieve top-line objectives\\nInterpreting business requirements and translating them into analytical objectives\\nPerforming root cause analysis on business problems while providing recommendations in a timely manner\\nInstilling a company wide-culture of data-first decision making and driving continuous data quality best practices\\nTHE QUALIFICATIONS\\n\\nBachelor’s degree in Analytics, Engineering, Statistics, Management Science, Applied Mathematics, or related field, with Master’s degree preferred\\n3+ years of experience in a high-paced, tech-first company, with financial services experience preferred\\nDemonstrable experience using data visualization tools such as Tableau or Google Data Studio\\nUnderstanding of how relational databases work, how objects are linked with each other, different types of joins, and how to use them for reporting\\nFamiliarity using complex nested condition loops (using functions such as If, Where, Case, etc) and using logical operators (such as AND, OR, NOT, etc)\\nStrong ability to understand how to use data to support and enhance business processes\\nAbility to work with large relational datasets and derive insights from the same\\nPrior work experience or coursework on Salesforce CRM is a plus\\nExcellent verbal and written communication, presentation and facilitation skills with the ability to express complex concepts in plain language to reach broader audiences\\nRoleData Analyst\\nIndustry TypeBanking\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.A in Statistics, B.Tech/B.E. in Any Specialization, B.Sc in Statistics\\nPG :Any Postgraduate\\nDoctorate :Doctorate Not Required\\nKey Skills\\nGoogle Data StudioData SupportData AnalysisData AnalystTableauAnalyticsSQL',\n",
       " 'Job description\\nRoles and Responsibilities\\n\\nDevelop and maintain various analytics reports and dashboards to provide actionable insights that support data-driven decision-making for the leadership teams.\\nTo drive process improvement and recommend all aspects of Manufacturing workflow, reporting, data integrity, and maintenance.\\nTo track cost through Management Information System, the targeted cost vs actual cost for departments like Marketing, Production, and assist the president in conducting monthly quarterly, & annual reviews with effective and efficient use of MIS.\\nTo engage and work with aligned operations teams and lines of business to more effectively achieve data needs and analysis results.\\nLooking for candidates with B.tech Textile background, interested candidates can drop the CV to roopa.bk@gokaldasexports.com/rose.thomas@gokaldasexports.com\\nRoleExecutive Data Analyst\\nIndustry TypeImport & Export\\nFunctional AreaExport, Import, Merchandising\\nEmployment TypeFull Time, Permanent\\nRole CategoryNot mentioned\\nEducation\\nUG :B.Tech/B.E. in Textile\\nPG :M.Tech in Production/Industrial, Textile\\nKey Skills\\nExcelExport HouseData ManagementData AnalysisDashboardsMerchandisingManufacturing Process',\n",
       " 'Job description\\nJob Responsibilities\\nManaging and ensuring data quality, integrity, normalization and accuracy of available datasets. Improve data quality as per data quality framework and working with data owner. Internal and external benchmarking to establish things influencing data quality.\\nManaging and designing the reporting environment, including data sources, security, and metadata. Generate business insights using BI dashboards that shall provide clear directions/actions to senior managers to support decision-making.\\nSupport digitization to improve quality of data. Root cause analysis by using quality analysis tools, machine learning and statistics.\\nHelping organization to take key decisions based on integrated analytics involving different datasets. Perform predictive data analysis, generate indications for focus area and target the improvements proactively.\\nMaintain and re-engineer existing ETLs to increase data accuracy, data stability, and pipeline performance.\\nAdvanced statistical techniques for complex data analysis. Interpreting data, analysing results using statistical techniques, developing analytical reports.\\nAdherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.\\nSufficient business acumen to understand business objectives dynamics\\nAs a data analyst, you will work with data from a wide range of sources. You will be taking responsibility for exploring the data, recommending actionable insights, building visualizations/dashboard to provide information that matters to business. This will involve automating data quality checks, data extraction and pre-processing. You will be the person who turns data into information, information into insights and insights into business decisions. You should also have a very fine eye for detail and deep understanding of the popular data analysis tools and databases. As data analyst you will create compelling reports using database-stored procedures and triggers. As the analytics team is chartered to be the one stop shop for all data needs, you will play an integral role in analytics team for the holistic growth of the businesses.\\nJob Qualifications:\\nBachelor s or masters degree in Computer Science, Information management, Statistics or related field\\n5+ years of experience in the Consumer or Healthcare industry in an analytical role with focus on querying data, analyzing and clearly presenting analyses to stakeholders across the organization.\\nWorking experience on Python, R Programming, Scala, Apache Spark, AWS Redshift is must.\\nMandatory working experience in QlikView, Adobe analytics, Google 360. Knowledge in analytics tools like Tableau, Power BI, Excel VBA Macros, RSPSS, SAS is an added advantage.\\nProven working experience as a data analyst or business data analyst. Experience in working on Business intelligence tools/platforms and systems.\\nStrong knowledge in data pre-processing and EDA by using various tools. Thorough in analytics/visualization tool setup, configuration and administration.\\nHaving knowledge of classification (Random Forest, SVM, Boosting and Bagging techniques) and clustering algorithms is desirable\\nHands on in Descriptive / Predictive / Prescriptive Analytical techniques. Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\\nResults driven with analytical and numeric skills. Convey data story through the visualization.\\nA team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.\\nAbility to work effectively and independently in a fast-paced agile environment with tight deadlines\\nA flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organisation.\\nRoleDatabase Architect/Designer\\nIndustry TypeMedical Services / Hospital\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\nData analysisSASAnalyticalHealthcareData qualityInformation managementBusiness intelligenceMacrosAnalyticsData extraction',\n",
       " '--',\n",
       " 'Job description\\nRoles and Responsibilities\\nData Analyst at Flipkart gets to work on end to end role\\nEnd to end: From Interacting with the stakeholders along with the team for requirement gathering to providing reports to the Business Analysts and providing insights\\nFlipkart has Tower Heads who are otherwise called as Stakeholders who classify the work and assign it across different teams\\nThe Data is stored in FDP, where data analyst are allowed to consume the data and provide insights. (FDP Flipkart Data Platform)\\nMajor role of a Data Analyst would be to ensure data quality, processing time and real time report generation\\nEvery action on the site involves analytics. Take for example a simple search query: how far did the user have to scroll down? If the search results are relevant, the user should be able to find the product they are looking for without needing to scroll too far down.\\nEfficiency also plays a vital part in customer experience. Where a product order comes from can help with inventory planning, delivery time, and so on. Then there are insights that are important for running the business, such as figuring out if product ratings are genuine or whether somebody is gaming the system for sales offers.\\nFlipkart gets 10 terabytes of user data each day from browsing, searching, buying or not buying, as well as behaviour and location. This jumps to 50 terabytes on Big Billion Day sales days. There is also order data, shipping data, and other forms of data captured by different systems. All this is mixed together and correlated for meaningful insights.\\n\\n\\nDesired Candidate Profile\\nShould be a quick learner with ability to learn new tools/technology quickly\\nGood analytical skills and ability to understand the business and be able to relate the same to data.\\nUnderstanding of ecommerce/retail business (preferred but not mandatory)\\nShould be result & detailed oriented and must have ability to multi task and work under pressure with minimum supervision in the fast paced ecommerce environment Proficient in Verbal and Written Communication skills, with demonstrated ability to communicate with all levels within the company\\nProven working experience as a data analyst or database expert\\nWorking experience on large data volume, building complex SQL queries & Optimising or performance tuning\\nUnderstanding regarding data models, database design development, data mining and segmentation techniques\\nStrong knowledge of and experience with reporting packages (Tableau, Power BI, etc)\\nKnowledge of statistics and experience using statistical packages for analysing datasets (Excel, SPSS, etc)\\nStrong ability to collect, organize, analyse, and disseminate significant amounts of information with attention to detail and accuracy\\nHands on experience in working with key stakeholders from products, returns, operations, and business finance to perform analysis on customer experience KPIs and metrics\\nFamiliar with scripting languages such as R and Python\\n\\nPerks and Benefits\\nWork on large data sets and work on real time data.\\nThe candidates will get to work on R/ Python > EDA\\nReport work on power BI within a time period of 15 day to 1 month\\nstakeholder management and collaborate with multiple teams like, business, finance, analytics etc which give the TE exposure to different divisions\\nConversion to SDA or BA\\nMonthly skill set training from FK school and skillsoft\\n\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryNot mentioned\\nEducation\\nUG :Any Graduate\\nKey Skills\\nExcelSQL\\nPower BiProblem SolvingAdvanced ExcelTableauQlikViewAnalytics\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " '--',\n",
       " '--',\n",
       " 'Job description\\nBusiness Title/Designation - Senior Associate / Assistant Manager\\n\\nRoles and Responsibilities\\nTranslate business requirements and hypotheses into analyses and insights to aid business decision making.\\nConduct full lifecycle activities which includes project requirement, data collection, data cleaning, data exploration/analysis, analytics, and client reporting\\nPartner with stakeholders at all levels to establish current and ongoing data support and reporting needs.\\nEnsure continuous data accuracy and recognize data discrepancies in systems that require immediate attention/escalation.\\nAbility to work with structured as well as unstructured data and derive meaningful insights\\nShould be able understand user requirements and articulate the same to the technology team\\nShould have excellent problem-solving skills. Should be able to work with management to prioritize business and information needs\\nMust be able to prioritize multiple assignments, with a high degree of accuracy, and function quickly in a fast-paced, deadline-oriented environment.\\nDeveloping and executing processes for monitoring data sanity, check for data availability.\\nTeam player with an eye for detail.\\nStrong logical & analytical thinking, verbal and written communication skills\\nWorks efficiently across distributed teams and should be comfortable working in Matrix Organization structure.\\nAptitude for learning new technologies and concepts\\nDesired Candidate Profile\\nBachelors Degree in Computer Science or equivalent experience and knowledge\\n3 - 7 years of experience in Data Analysis, Reporting or MIS\\nHighly organized, technically sound & good at communication\\nData driven and problem solver\\nStrong expertise in communication, presentation skills\\nKnowledge of various BI tools desirable\\nRoleData Analyst\\nIndustry TypeAccounting / Auditing\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nTableauETL\\nBI ToolsProject RequirementAlteryxData ExplorationData CollectionReportingMIS ReportingMISData AnalysisData CleaningVBA Macros\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nPrimary responsibility of the Senior Data Analyst will be to build and maintain the dashboard platform/processes and to address to any data related needs of the organization. This role will work across functions with other groups in analytics as well as other departments in the company and will be expected to frequently work on data requests from various stakeholders.\\nExpectations from the role: Create and maintain reporting tools and applications to support all strategic and tactical needs of the company Dashboard development and generation for daily, weekly, monthly and all reporting needs. Gather user requirements for new reports and enhance existing reports. Interpret needs and design reports to meet end user expectations. Data modeling, and creation of both logical and physical data models for effective and efficient reporting and TAT on frequent requests Design and develop complex data queries to move and transform data from operational data sources to analytical databases.\\nTest all new reports/deliverables and periodically review them for quality control. Data validation and attention to detail is required as this role will be accountable for quality of all the numbers delivered through dashboards or otherwise. Work effectively as part of a team to achieve individual, team and organizational objectives, sharing knowledge and skills. Positively work and influence with team members to partner together to achieve individual, customers and business goals\\nRequired Technical Skills: Strong experience in building complex SQL queries Advanced Excel & Macros. Strong logical & analytical concepts in databases, schemas, dimensional modellingEnd-toend Experience in building complex MIS and dashboards especially in Qlikview Programming languages like VB, JAVA, C will be good to have Experience in QlikView and Hadoop is highly desirable but not mandatory\\nRequired Behavioral Skills: Should be a quick learner with ability to learn new tools/technology quickly Good analytical skills and ability to understand the business and be able to relate the same to data. Understanding of ecommerce/retail business (preferred but not mandatory) Should be result & detailed oriented and must have ability to multi task and work under pressure with minimum supervision in the fast paced ecommerce environment Proficient in Verbal and Written Communication skills, with demonstrated ability to communicate with all levels within the company\\nRoleDatabase Architect/Designer\\nIndustry TypeInternet\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :Post Graduation Not Required\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData validationMISData AnalystManager Quality ControlQlikViewVBMacrosOperationsAnalyticsReporting tools',\n",
       " 'Job description\\nAbout the role:\\nData Analyst is an Individual Contributor role where you will be responsible for tracking key metrics through building and maintaining data pipelines and dashboards for visualization. Along with this, you will be expected to have a very good handle on different data streams and address the organization s data requirements. This role will work across functions with other groups in analytics as well as other departments in the company and will be expected to frequently work on data requests from various stakeholders\\nWhat you ll do:\\nGather user requirements for new reports and enhance existing reports. Interpret needs and design reports to meet end user expectations\\nCreate and maintain reporting tools and applications to support all strategic and tactical needs of the company. Dashboard development and generation for daily, weekly, monthly and all reporting needs\\nDesign and develop complex data queries to move and transform data from operational data sources to analytical databases\\nTest all new reports/deliverables and periodically review them for quality control\\nWhat you ll need:\\nTechnical capabilities:\\nStrong experience in SQL - should be able to build complex and optimized queries\\nStrong experience in Excel - should be comfortable with advanced functions. Understanding of macros is beneficial\\nStrong logical & analytical concepts in databases, schemas, dimensional modelling\\nGood to have : Basic understanding of scripting languages (R, Python, etc.)\\nGood to have : Experience with BI tools (Power BI, Tableau, Qlikview, Datastudio, etc)\\nGood to have : Working knowledge of data warehousing infra tools like Hive\\nRequired abilities / competencies:\\nAttention to detail and strong data orientation\\nAbility to adapt to and learn new tools/ techniques quickly\\nVery good written and verbal communication skills\\nAbility to multitask and work on a diverse range of requirements\\nStrong rigor in automating repetitive tasks\\nGood to have: understanding of ecommerce/ retail business\\nWork ex:\\n3 Years of experience in relevant role\\nRoleBusiness/EDP Analyst\\nIndustry TypeInternet\\nFunctional AreaITES, BPO, KPO, LPO, Customer Service, Operations\\nEmployment TypeFull Time, Permanent\\nRole CategoryOperations\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nDoctorate :Doctorate Not Required\\nKey Skills\\nAnalyticalData AnalystManager Quality ControlQlikViewMacrosOperationsAnalyticsReporting toolsSQLPython',\n",
       " 'Job description\\nJob Title: Sr Associate- Data Analyst\\n\\nExperience: 3 - 5 Years\\n\\nLocation: Bengaluru\\n\\nNotice Period: Immediate to 30 Days\\n\\nResponsibilities:\\n\\n- Make data sets useful and meaningful by presenting key information needed for business insight and decision making\\n\\n- Aid in development of analytics and reporting for businesses\\n\\n- Develop data analytics capability within business finance through power users\\n\\n- Provide business expertise in more advanced analytics and delivery of insights\\n\\n- Provide challenge & marginal analysis capability to all requests for work thereby ensuring workload is strategically prioritized\\n\\n- Think through a business problem and come up with a set of hypotheses\\n\\n- Create a list of potentially relevant supporting data elements\\n\\n- Work with data engineers and/or data scientist to procure data and test it for problems\\n\\n- Experience working on Time series data\\n\\n- Experience in data mining techniques and methodologies (data prep/modeling, classification, regression, clustering, causal modeling, AI, machine learning, ensemble approaches)\\n\\nSkills required:\\n\\n- SQL\\n\\n- Python\\n\\n- Power BI\\n\\nGood to have:\\n\\n- Denodo\\n\\n- Redshift\\n\\n- Matillion (ETL/ELT)\\n\\n- Critical Thinking Skills\\n\\n- MS Excel\\n\\n- AWS\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Any Specialization, BCA in Computers, B.Tech/B.E. in Any Specialization\\nPG :Any Postgraduate\\nDoctorate :Doctorate Not Required\\nKey Skills\\nPower BIData AnalystData AnalyticsETLPythonSQL',\n",
       " 'Job description\\nYour Role :\\n\\n- Head end to end learning experience of Data analytics career track and related courses\\n\\n- Manage team to design and build best in class employment focused learning products\\n\\n- Work with other Learning Experience team such as Content, Delivery, Student Success and Corporate Partnerships to drive over action plans\\n\\n- Develop industry relevant assignment, projects and check them on time\\n\\n- Resolve students queries of students and take demo sessions\\n\\n- Managing Industry experts, mentors and Placement partner- to develop and deliver best in class learning experience\\n\\n- Coordinate with Industry experts or companies to define and structure the curriculum according to industry needs and plan end to end delivery\\n\\n- Create engaging learning activities to increase learning experience of the students Develop and maintain academic policies and standards for mentors/TA/curriculum team\\n\\n- Provide academic insights to develop products to enhance customer engagement and placement performance\\n\\n- Design learning objectives, structure learning activities, online competition/leagues to increase student engagement\\nRoleData Analyst\\nIndustry TypeE-Learning / EdTech\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData AnalystData AnalyticsAnalyticsSQLPython',\n",
       " 'Job description\\nNear is looking for a Lead - Data Analyst to join our team as we scale globally. You will be a key member of the Analytics, Research Insights team, delivering critical data-driven insights across the organization as well as to partners. You will be responsible for extracting data from various sources, building intelligence from it, and presenting it appealingly to empower effective data-driven decision-making through surfacing the most relevant insights from data; through reporting, analysis, and optimization.\\nYou will be part of one of the fastest-growing Enterprise SaaS companies and a great opportunity for people who can work independently and are self-driven.\\n\\n\\nA Day in the Life\\nUnderstanding business requirements and translating it into executable steps for the team members.\\nCollaborate with product managers and suggest appropriate solutions for analytics deliverables.\\nDeep understanding of different data sources and using the best of it for the use cases.\\nOptimize code for maximum efficiency and review the team s code to identify bugs and logical gaps.\\nBuild reusable code and libraries for future use.\\nReview the team s deliverables before sending final reports to stakeholders.\\nGet feedback and build solutions for users and customers.\\nSynthesize both quantitative and qualitative data into insights that deepen our understanding of our product performance and user behaviour.\\nSupport cross-functional teams with data reports and insights on data.\\nStay up to date on emerging technologies and skills.\\n\\n\\nWhat You Bring to the Role\\nYou should hold a B.Tech / M.Tech degree.\\n6+ Years of experience; should have worked with SQL, Python and Big Data Technologies, SQL and NoSQL Databases.\\nShould be adept at understanding business requirements and translating them into code.\\nShould have a proven record of prior BI/reporting experience.\\nExpertise in analyzing data and query authoring.\\nExperience in structured analysis and query optimization in SQL.\\nExperience with any Data Visualization tool will be a plus.\\nPassionate about learning new technologies.\\nExceptional problem solving, analytical and organizational skills with an eye for detail.\\nRoleSystem Analyst\\nIndustry TypeFilm / Music / Entertainment\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E.\\nPG :M.Tech in Electronics/Telecommunication\\nKey Skills\\nData ScienceContent MarketingProblem SolvingBig DataData EngineerData VisualizationData AnalystData AnalyticsPythonSql',\n",
       " 'Job description\\nResponsibilities\\nBuild and deploy standardized metrics and dashboards for the company s leadership team\\nAssist product and operations to insure that data remain accurate as new processes are applied\\nAssist in creating a single source of truth for Acquisition, Activation, Retention, Revenue and Referral product usage data\\nAssist engineering and product to analyze trends in product usage\\nWork with the product management team to prioritize requirements for business reporting\\nUse data to create models that depict trends in the customer base and the consumer population as a whole\\nWork effectively with cross-functional teams\\nPerform ad-hoc and in-depth analysis\\nRequirements:\\n2-5 years experience in business or data analytics\\nAbility to work independently and as a member of a cross-functional team\\nProven ability leveraging analytical and problem-solving skills in a fast paced environment\\nStrong communicator, both written and verbal\\nBachelor s degree in computer science, data science, finance, or equivalent work experience\\nSQL and advanced Excel experience required.\\nExperience in building dashboards and models and proficiency with BI software\\nBonus points for experience with regressions and other predictive models\\nRoleProduct Manager\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Systems, EDP, MIS\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nData ScienceProduct ManagementJobsFinanceMedicalData AnalyticsMachine LearningRecruitment',\n",
       " 'Job description\\nUrgent hiring for Data Analyst/ Sr.Data Analyst for Bangalore Location, please find the job responsibility as below:-\\nJob Profile : Data Analyst/ Sr.Data Analyst\\nExperience : 2- 10 years\\nWorking Days :Monday-Friday\\nLocation :Bangalore\\nKey responsibilities and accountability:\\n1. 5+years hands-on experience\\n2. Basic programming skill in either Python or SQL/Hive, with strong data extraction experience\\n3. Experience of working on HDFS(Good to Have, not mandatory)--- this is just addon, dont look for data engineers\\n4. Data querying and manipulation\\n5. Databases [Excel, SQL Server, Hadoop, Hive]\\n6. Reporting tools [PowerBI]\\n\\nContact-9479715871\\nRoleData Analyst\\nIndustry TypeAnalytics / KPO / Research\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nKey Skills\\nData Mining data analysisData Visualization power biData Analytics Tableau hive Data Scientist',\n",
       " 'Job description\\nRole Overview:\\nThis position provides insights surrounding the digital journey of our customers and how it relates to content and campaign development, efficacy and return on investment. This role will focus on blending traffic data with internal CRM data and will require data extraction, cleansing, and transformation, in preparation for analysis by the individual, other team members and our media agency. Keys to success include a natural curiosity, willingness to dig deep to uncover insights, and dedication to maintaining an elite level of accuracy. This cross-functional role will rely heavily on the input of others and a solid understanding of a complex end-to-end marketing and sales cycle.\\n\\nAbout the role:\\nAdvanced data modeling including extraction, transformation and governance, and quality assurance\\nProviding recurring and ad-hoc reports through PowerBI, Excel, PowerPoint, custom dashboards and more.\\nProviding analysis of digital marketing campaigns and defining relationships between marketing actions and financial outcomes to raise increase profitability.\\nWorking with Marketing Managers to identify opportunities and shortcomings including review of key performance indicators, design/review of A/B testing and custom analysis.\\nBuilding and maintaining digital marketing dashboards that visualize key performance indicators while also providing drill-down ability to gain deeper knowledge.\\nIntegrating external marketing information within the company system to support views along the buyer s journey from early awareness through to consideration and purchase.\\nMonitoring and tracking website traffic and downloads throughout the user session and how this information relates to campaign specific actions.\\nAbout you:\\nExceptional knowledge of database architecture, data visualizations and analysis\\nStrong understanding of Alteryx or other ETL tools required\\nExpertise in PowerBI preferred, consideration for similar visualization tools\\nWorking knowledge of APIs, JSON, and XML preferred\\nBasic understanding of Adobe Analytics or equivalent web reporting solution\\nExperience with Python for Statistical Modeling and Integration with Data Visualization tools is a plus.\\nStrong business acumen, analytical and problem-solving skills\\nStrong business reporting, project management and writing skills\\n\\n\\nRoleMarketing Manager\\nIndustry TypeIT Services & Consulting\\nFunctional AreaMarketing, Advertising, MR, PR, Media Planning\\nEmployment TypeFull Time, Permanent\\nRole CategoryMarketing\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\nManager Quality AssuranceData modelingProject managementXMLAnalyticalData AnalystDigital marketingMonitoringCRMData extraction']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting the full job description from each of the urls \n",
    "desc=[]\n",
    "for i in job_url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_desc=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        desc.append(job_desc.text)\n",
    "    except:\n",
    "        desc.append(\"--\")\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_required</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst IDAM Services</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\n  Identity and Access Managem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst/Sr.Data Engineer</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Job description\\nResponsibilities:\\nProvide in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nDear Candidates\\n\\nWe have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nDear Candidates\\n\\nWe have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nYour responsibilities will in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Executive Data Analyst</td>\n",
       "      <td>Gokaldas Exports Ltd</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - I/II</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nJob Responsibilities\\nManagin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For the role - DATA Analyst (Flipkart)</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For the role - DATA Analyst (Flipkart)</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_title  \\\n",
       "0                 Senior Data Analyst IDAM Services   \n",
       "1                     Data Analyst/Sr.Data Engineer   \n",
       "2                             Business Data Analyst   \n",
       "3                             Business Data Analyst   \n",
       "4  Business Data Analyst - Google Data Studio & SQL   \n",
       "5                            Executive Data Analyst   \n",
       "6                               Data Analyst - I/II   \n",
       "7                                      Data Analyst   \n",
       "8     Hiring For the role - DATA Analyst (Flipkart)   \n",
       "9     Hiring For the role - DATA Analyst (Flipkart)   \n",
       "\n",
       "                                   Company Experience_required  \\\n",
       "0  GlaxoSmithKline Pharmaceuticals Limited             4-8 Yrs   \n",
       "1       SYREN TECHNOLOGIES PRIVATE LIMITED             4-9 Yrs   \n",
       "2                         Trigent Software            5-10 Yrs   \n",
       "3                         Trigent Software            5-10 Yrs   \n",
       "4                             AVE-Promagne             3-8 Yrs   \n",
       "5                     Gokaldas Exports Ltd             0-3 Yrs   \n",
       "6                    Philips India Limited             3-6 Yrs   \n",
       "7                   IBM India Pvt. Limited             1-4 Yrs   \n",
       "8         Allegis Services India Pvt. Ltd.             1-6 Yrs   \n",
       "9         Allegis Services India Pvt. Ltd.             1-6 Yrs   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bengaluru/Bangalore   \n",
       "8  Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...   \n",
       "9  Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...   \n",
       "\n",
       "                                     Job_description  \n",
       "0  Job description\\n  Identity and Access Managem...  \n",
       "1  Job description\\nResponsibilities:\\nProvide in...  \n",
       "2  Job description\\nDear Candidates\\n\\nWe have a ...  \n",
       "3  Job description\\nDear Candidates\\n\\nWe have a ...  \n",
       "4  Job description\\nYour responsibilities will in...  \n",
       "5  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "6  Job description\\nJob Responsibilities\\nManagin...  \n",
       "7                                                 --  \n",
       "8  Job description\\nRoles and Responsibilities\\nD...  \n",
       "9                                                 --  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a Dataframe\n",
    "data=list(zip(Title,Company,Experience,Location,desc))\n",
    "job=pd.DataFrame(data=data,columns=[\"Job_title\",\"Company\",\"Experience_required\",\"Location\",\"Job_description\"])\n",
    "job=job[0:10]\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q -2 Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ae5790048aa8b3e23445e048fab20077\", element=\"d0468878-d2bb-4d7d-afbd-47f27216d7a2\")>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_skill=driver.find_element_by_xpath(\"//input[@id='qsb-keyword-sugg']\")\n",
    "search_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for data Scientist \n",
    "search_skill.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for bangalore\n",
    "s_l=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "s_l.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "s.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead Data Scientist BFSI',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Senior Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " 'Hiring For Data Scientist / Statistical Analyst',\n",
       " 'Sr Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Freelance Data Scientist Project Based',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - ML',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Cognitive Data Scientist']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping job title\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "T=[]\n",
    "for i in title:\n",
    "    T.append(i.text)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM India Pvt. Limited',\n",
       " 'Philips India Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Airbnb',\n",
       " 'Happiest Minds Technologies Pvt.Ltd',\n",
       " 'AVE-Promagne',\n",
       " 'ManpowerGroup Services India Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'Shikvix',\n",
       " 'NeenOpal Intelligent Solutions Private Limited',\n",
       " 'PRESCIENCE DECISION SOLUTIONS PRIVATE LIMITED',\n",
       " 'CRISIL LIMITED',\n",
       " 'ELPIS IT SOLUTIONS PVT LTD',\n",
       " 'ELPIS IT SOLUTIONS PVT LTD',\n",
       " 'SP Staffing Services Private Limited',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping Company name \n",
    "c=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "Com=[]\n",
    "for i in c:\n",
    "    Com.append(i.text)\n",
    "Com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Remote',\n",
       " 'Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bengaluru/Bangalore']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping location \n",
    "l=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "L=[]\n",
    "for i in l:\n",
    "    L.append(i.text)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-9 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '7-12 Yrs',\n",
       " '5-10 Yrs',\n",
       " '6-8 Yrs',\n",
       " '2-4 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-11 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '2-6 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '10-15 Yrs',\n",
       " '5-9 Yrs',\n",
       " '2-4 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping experience \n",
    "e=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "EX=[]\n",
    "for i in e:\n",
    "    EX.append(i.text)\n",
    "EX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-lead-data-scientist-bfsi-ibm-india-pvt-limited-bengaluru-bangalore-5-to-9-years-070921901691?src=jobsearchDesk&sid=1631135544569272&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-philips-india-limited-bangalore-bengaluru-3-to-5-years-060921501985?src=jobsearchDesk&sid=1631135544569272&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-070921901677?src=jobsearchDesk&sid=1631135544569272&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-airbnb-bangalore-bengaluru-7-to-12-years-080921500017?src=jobsearchDesk&sid=1631135544569272&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-happiest-minds-technologies-pvt-ltd-bangalore-bengaluru-5-to-10-years-070921501517?src=jobsearchDesk&sid=1631135544569272&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-sql-ave-promagne-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-8-years-060921904967?src=jobsearchDesk&sid=1631135544569272&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-data-scientist-statistical-analyst-manpowergroup-services-india-private-limited-bangalore-bengaluru-2-to-4-years-080921011029?src=jobsearchDesk&sid=1631135544569272&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-6-to-8-years-010921906637?src=jobsearchDesk&sid=1631135544569272&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-6-to-8-years-010921906105?src=jobsearchDesk&sid=1631135544569272&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bangalore-bengaluru-6-to-11-years-080221900886?src=jobsearchDesk&sid=1631135544569272&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-freelance-data-scientist-project-based-shikvix-bangalore-bengaluru-3-to-8-years-060921008814?src=jobsearchDesk&sid=1631135544569272&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-neenopal-intelligent-solutions-private-limited-bangalore-bengaluru-2-to-5-years-080921006998?src=jobsearchDesk&sid=1631135544569272&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-prescience-decision-solutions-private-limited-bangalore-bengaluru-5-to-10-years-080921005624?src=jobsearchDesk&sid=1631135544569272&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-requirement-for-data-scientist-mumbai-bangalore-crisil-limited-bangalore-bengaluru-mumbai-all-areas-2-to-6-years-080921005523?src=jobsearchDesk&sid=1631135544569272&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-elpis-it-solutions-pvt-ltd-bangalore-bengaluru-3-to-8-years-070921602158?src=jobsearchDesk&sid=1631135544569272&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-elpis-it-solutions-pvt-ltd-bangalore-bengaluru-3-to-8-years-070921002157?src=jobsearchDesk&sid=1631135544569272&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-ml-sp-staffing-services-private-limited-pune-chennai-bangalore-bengaluru-10-to-15-years-100621006203?src=jobsearchDesk&sid=1631135544569272&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-oracle-india-pvt-ltd-noida-bangalore-bengaluru-5-to-9-years-010621004567?src=jobsearchDesk&sid=1631135544569272&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-2-to-4-years-010921906678?src=jobsearchDesk&sid=1631135544569272&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-cognitive-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-030921904668?src=jobsearchDesk&sid=1631135544569272&xp=20&px=1']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=[]\n",
    "for i in title:\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " 'Job description\\nUse predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomes\\nWork with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled.\\nSelecting features, building and optimizing classifiers using machine learning and deep learning techniques\\nCollaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nDevelop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models.\\nAdherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.\\nJob Qualifications:\\nMaster s degree or PhD in Computer Science, Information management, Statistics or related field, with 3 to 5 years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product development\\nExperience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc.\\nStrong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etc\\nHaving strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learning\\nStrong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners.\\nDeep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalent\\nExperience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools.\\nProficiency in using query languages, such as SQL, PL/SQL\\nHands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc.\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\\nGood ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition.\\nA team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.\\nAbility to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlines\\nA flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization.\\nA self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data science\\nRoleClinical Research Associate/Scientist\\nIndustry TypeMedical Services / Hospital\\nFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology\\nEmployment TypeFull Time, Permanent\\nRole CategoryR&D\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\nProduct managementComputer sciencemetadataMachine learningAgilePLSQLHealthcareQlikViewData miningPython',\n",
       " '--',\n",
       " 'Job description\\nResponsibilities include:\\nDefining and evaluating key metrics and understanding what moves them and why\\nOwnership of conceptualizing, developing, and maintaining dashboards and visualizations\\nInvestigating evolving fraud trends to extract patterns, identify root causes and propose actionable solutions\\nCommunicating analyses and recommendations to cross functional stakeholders for decision making\\nEmpowering the team to answer data questions quickly and easily by building high-quality ground truth data sets\\nHere are example traits we value:\\nProfessional industry experience in a quantitative analysis role (7+ years preferred)\\nComfortable in SQL and some experience with a programming language (Python or R a plus)\\nAbility to communicate clearly and effectively to cross functional partners of varying technical levels\\nAbility to define relevant metrics that can guide and influence stakeholders to the appropriate and accurate insights\\nExperience or willingness to learn tools to create data pipelines using Airflow\\nBuilding clear and easy to understand dashboards (Tableau) and presentations\\nRoleGraphic/Web Designer\\nIndustry TypeInternet\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nData ScienceRData ScientistTableauPythonSql',\n",
       " 'Job description\\n  Skills\\nRequired Skills: Data Science, Machine Learning, Deep Learning, Python, NLP\\nDesired Skills: Computer Vision\\nRoles and responsibilities\\nExperience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, NLP, Statistics\\nHave ability to solve Business problems using Data\\nShould possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets\\nHigh level of proficiency in statistical tools like R, Python\\nCandidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.\\nHave the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems\\nGood to Have\\nExpertise in programming languages like Java/C/C /Python\\nExperience with relational databases and SQL is good to have\\nExperience in audio and video analytics\\nRelevant experience in Big Data platforms like Hadoop eco-system\\nCome up with innovative algorithms and solutions\\nStaffing Type:Permanent\\nRoleClinical Research Associate/Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology\\nEmployment TypeFull Time, Permanent\\nRole CategoryR&D\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nHospitalityNSEStaffingBfsiAnalyticalAgileData miningAnalyticsAutomotiveSQL',\n",
       " 'Job description\\nRequired Technical and Professional Expertise\\n• 6+ years of industry work experience in data scientist projects\\n• Master’s degree or higher in Statistics/Math/Computer Science or related field\\n• Background in applied statistical modeling on large experimental or observational data sets\\n• Experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge SQL is required, Spark is a plus)\\n• Experience with one or more statistical or machine learning software such as R, Python, etc.\\n• Must showcase past work through published articles/GitHub/social media\\n\\nPreferred Technical and Professional Expertise\\n• Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management system\\n• PhD. in Statistics is preferred\\n• You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies\\n• Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work\\n• Intuitive individual with an ability to manage change and proven time management\\n• Proven interpersonal skills while contributing to team effort by accomplishing related results as needed\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Maths, Statistics\\nPG :MS/M.Sc(Science) in Maths, Statistics\\nDoctorate :Doctorate Not Required\\nKey Skills\\nRData scienceData analyticsSQLPython',\n",
       " 'Job description\\nDepartment- BIRS (Business Intelligence Risk Solutions)\\n\\nJD Statistical Analyst/ Data scientist:\\nClient oriented approach to problem solving. Individual should be able to have a holistic view of multiple businesses and develop analytic solutions accordingly.\\nOwn and deliver multiple and complex analytic projects. This would require an understanding of business context, conversion of business problems in modeling, and implementing such solutions to create business value.\\nAlways up to date with the latest use cases of modeling community, machine learning and deep learning algorithms and share knowledge within the team.\\nProficiency in basic statistics, hypothesis testing, segmentation and predictive modeling.\\nAbility to translate and articulate technical thoughts and ideas to a larger audience including influencing skills with peers and senior management.\\nStrong project management skills.\\nAbility to coach and mentor juniors.\\nEagerness to work on new and challenging tasks on a regular basis with an ability to research new ways of doing things better/efficiently.\\nContribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.\\nBasic Qualifications\\n\\nBachelor’s Degree with 2+ years of experience in data analytics,\\nHands-on experience in Python / SAS or R programing along with strong experience in SQL and Excel Macros.\\nExperienced in working with large and multiple datasets, data warehouses and ability to pull data using relevant programs and coding.\\nWell versed with necessary data preprocessing and feature engineering skills.\\nAt least 2 years of experience implementing Machine learning algorithms such as Random Forest and Gradient Boosting in solving business problems such as Default classification and macroeconomic forecasting.\\nAt least 1 year of experience implementing deep learning techniques like neural networks\\nExposure to deep learning packages like Tensorflow\\nStrong background in Statistical Analysis\\nBackground in BFSI space will be preferredRoles and Responsibilities\\n\\nIf anyone interested, please share your resume to below mail id:-\\n\\nSoundarya.s@manpower.co.in;\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nKey Skills\\nTensorflowPredictive ModelingRNeural NetworksMachine LearningStatistical AnalysisDeep LearningPythonRandom ForestSQL',\n",
       " '--',\n",
       " '--',\n",
       " 'Job description\\nRoles and Responsibilities\\nRequirements :\\n\\n- 6-9 years of strong experience in data mining, machine learning and statistical analysis.\\n\\n- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Python/ R/ Matlab etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Computers, Statistics\\nPG :MS/M.Sc(Science) in Computers, Statistics\\nDoctorate :Ph.D/Doctorate in Statistics, Computers\\nKey Skills\\nData ScienceRData ScientistData MiningStatistical AnalystMachine LearningMATLABPython',\n",
       " \"Job description\\n\\nJob description:\\n\\nSeeking senior data scientists for project-based roles that involve working on various projects.\\n\\nThe candidate must have experience in Python coding language and machine learning. The candidate will be working on a part-time basis and hours will be flexible based on the candidate's availability.\\nOpportunity to grow in a startup setting.\\nWhat you'll need:\\nB.Tech in CS or Statistics with demonstrable experience of over 5 years through publications/deployed solutions/projects.\\nM.Tech or Ph.D. in CS or Statistics with demonstrable experience of over 3 years through publications/deployed solutions/projects.\\nA deep understanding of applied statistical analysis and predictive modeling is desired.\\nThe candidate must have a thorough grasp of the theory and application of broad ML algorithms namely, but not limited to regression, SVM, Tree, Random Forests, Boosting, Neural Network, clustering, forecasting, deep learning, text analysis, etc.\\nIt is not expected that the candidate has actually worked on all these modules.\\nStrong proficiency in Python or R is necessary\\n\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypePart Time, Freelance/Homebased\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nKey Skills\\nPredictive ModelingRAlgorithmsSVMClusteringMachine LearningStatistical AnalysisStatisticsDeep LearningPython\",\n",
       " 'Job description\\nRoles and Responsibilities\\nWe are looking for someone who would be responsible for analyzing data and providing business insights. As a Data Scientist your responsibilities will include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand.\\nMoreover, you are expected to learn fast and deliver quickly in a fast-paced startup environment. If you thrive on ambiguity and are a problem solver and yet deliver value to clients, feel free to reach out to us.\\nWe are looking ONLY FOR SELF DRIVEN INDIVIDUALS with a desire to excel in Data Science Domain.\\nUnderstanding business objectives and developing models that help to achieve them, along with metrics to track their progress\\nDevelop and maintain robust data processing pipelines and reproducible modeling pipelines\\nBuild mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines.\\nAnalyze experimental results, iterate and refine models to create significant business impact\\nFollow strict coding standards and other software engineering best practices\\n\\n\\nDesired Candidate Profile\\nProven experience as a Data Scientist or similar role\\nStrong SQL, R/Python Skills\\nShould have familiarity with Machine Learning Models and fundamentals in Forecasting and Optimization Techniques\\nShould have strong mathematical background & analytical bent of mind\\nStrong Problem-Solving Ability\\nAbility to communicate well in a highly collaborative team environment, consisting of both technical and non-technical personnel\\nReliable self-starter that is capable of working with a high degree of autonomy\\n\\n\\nPerks and Benefits\\n\\nNeenOpal is a global management consulting firm with a unique and specialized focus on Data Science.\\nWe provide services across the whole value chain of an organization - Digital Strategy, Sales & Marketing, Supply Chain & Logistics as well as Finance. Youll have a blast doing it in our fun, passionate environment.\\nRoleData scientist\\nIndustry TypeManagement Consulting\\nFunctional AreaIT Software - Other\\nEmployment TypeFull Time, Permanent\\nRole CategoryNot mentioned\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nData SciencePythonSQL\\nExcelSoftware EngineeringProblem SolvingNeural NetworksTime SeriesData AnalysisBusiness InsightsData ProcessingMachine Learning\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nHi,\\n\\nWe at Prescience www.prescienceds.com looking for Data Scientist @ Bangalore .\\n\\nRoles and Responsibilities\\nAs a Data Scientist you will be working with senior management of clients to understand the business requirements, define right problem statement and come up with a framework for the solution. You will also work on the solution and at time guide a small team to deliver the same. Part of job role would be develop products in the area of Natural Language Processing, Conversational Interfaces, Text Mining etc.\\n\\nDesired Candidate Profile\\nWhat we are looking for:\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc. Experience in Natural Language Processing, Computer Vision. Exposure to common data science business problems like clustering, classification, anomaly detection, prediction etc.\\nGood understanding of machine learning techniques and algorithms\\nExperience with common data science toolkits Python, R, SAS\\nProficiency in using query languages such as SQL, Hive, etc Experience with NoSQL database, SQL Server, PostgreSQL, MongoDB\\nGreat communication skills\\nData-oriented personality and excellent business analysis skills\\nExperience in solutioning for data science related problems, work with business stakeholders to define right problem statement and solution.\\nOpen to professionals who have data analytics / BI background and then moved to Data Scientist roles.\\n\\nPerks and Benefits\\n\\n\\nRoleOther\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :Any Graduate\\nKey Skills\\nTensorflowPostgreSQLNatural Language ProcessingNeural NetworksMachine LearningStatisticsSQLData ScienceAnomaly DetectionPytorchRNLPMongoDBQlikViewComputer VisionData AnalyticsPython',\n",
       " 'Job description\\n\\nCRISIL (formerly Credit Rating Information Services of India Limited) is an Indian analytical company providing ratings, research, and risk and policy advisory services and is a subsidiary of American company S&P Global\\n\\nWe are looking Data Scientist for Mumbai & Bangalore location\\nCandidates who can join immediately or within 30-45 need only apply\\n\\nPlease refer below JD for your reference-\\n\\nJob Description Data scientist:\\nClient oriented approach to problem solving. Individual should be able to have a holistic view of multiple businesses and develop analytic solutions accordingly.\\nOwn and deliver multiple and complex analytic projects. This would require an understanding of business context, conversion of business problems in modeling, and implementing such solutions to create business value.\\nAlways up to date with the latest use cases of modeling community, machine learning and deep learning algorithms and share knowledge within the team.\\nProficiency in basic statistics, hypothesis testing, segmentation and predictive modeling.\\nAbility to translate and articulate technical thoughts and ideas to a larger audience including influencing skills with peers and senior management.\\nStrong project management skills.\\nAbility to coach and mentor juniors.\\nEagerness to work on new and challenging tasks on a regular basis with an ability to research new ways of doing things better/efficiently.\\nContribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.\\nSkills\\n\\nBasic Qualifications\\n\\nBachelors Degree with 2+ years of experience in data analytics,\\nHands-on experience in Python / SAS or R programing along with strong experience in SQL and Excel Macros.\\nExperienced in working with large and multiple datasets, data warehouses and ability to pull data using relevant programs and coding.\\nWell versed with necessary data preprocessing and feature engineering skills.\\nAt least 2 years of experience implementing Machine learning algorithms such as Random Forest and Gradient Boosting in solving business problems such as Default classification and macroeconomic forecasting.\\nAt least 1 year of experience implementing deep learning techniques like neural networks\\nExposure to deep learning packages like Tensorflow\\nStrong background in Statistical Analysis\\nBackground in BFSI space will be preferred\\n\\nRoleData Analyst\\nIndustry TypeBanking\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nrMachine LearningPython\\nTensorflowPredictive ModelingSegmentationNeural NetworksDeep LearningRandom ForestSQL\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nRoles and Responsibilities\\nJob Description:\\nDevelop data powered insights deriving from distributed, real time streaming applications, and develop AI systems leveraging on such data powered insights.\\nLooking for candidates with passion and energy to work in a high energy team with entrepreneurial culture: Self starter attitude, quick learning aptitude, passion and willingness to deliver on time with quality.\\n\\nJob Skills Required:\\nExpert data science skills using supervised and unsupervised learning. Deep learning.\\nCompute: Spark/Storm/NiFi/Flink/Redis, or other.\\nVisualization: Banana UI, Kibana, or other,\\nTools: H2O, TensorFlow, Mlib, Scikit, Keras or other.\\nMessaging: Kafka, RabbitMQ, or other.\\n\\nStrong Analytical and Math/Statistics skills.\\n\\nQualification :\\nM.Tech/M.E./M.S. in Computer Science, Engineering or a related field, preferably with a concentration, major or minor in Data Science or Machine Learning. PhD would be added advantage.\\n\\nDesired Candidate Profile\\nDesirable s that would strengthen candidacy:\\n Proven track record from public competitions such as from Kagel, Analytics Vidya, etc. \\n\\nExpertise in one or more high level programming languages such as Java, Scala, Python, Go, Erlang, etc.\\n\\nExpertise in developing scalable applications in a distributed environment.\\n\\nStrong SQL or NoSQL skills with one or more open source DBMS such as MySql, MongoDB, Cassandra.\\n\\nExpertise in containerized environments on private or public clouds - Aws Azure, etc.\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Temporary/Contractual\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\ndeep learningKibanatensorflowdata scienceKafkakerasSparkMachine Learning',\n",
       " 'Job description\\nRoles and Responsibilities\\nJob Description:\\nDevelop data powered insights deriving from distributed, real time streaming applications, and develop AI systems leveraging on such data powered insights.\\nLooking for candidates with passion and energy to work in a high energy team with entrepreneurial culture: Self starter attitude, quick learning aptitude, passion and willingness to deliver on time with quality.\\n\\nJob Skills Required:\\nExpert data science skills using supervised and unsupervised learning. Deep learning.\\nCompute: Spark/Storm/NiFi/Flink/Redis, or other.\\nVisualization: Banana UI, Kibana, or other,\\nTools: H2O, TensorFlow, Mlib, Scikit, Keras or other.\\nMessaging: Kafka, RabbitMQ, or other.\\n\\nStrong Analytical and Math/Statistics skills.\\n\\nQualification :\\nM.Tech/M.E./M.S. in Computer Science, Engineering or a related field, preferably with a concentration, major or minor in Data Science or Machine Learning. PhD would be added advantage.\\n\\nDesired Candidate Profile\\nDesirable s that would strengthen candidacy:\\n Proven track record from public competitions such as from Kagel, Analytics Vidya, etc. \\n\\nExpertise in one or more high level programming languages such as Java, Scala, Python, Go, Erlang, etc.\\n\\nExpertise in developing scalable applications in a distributed environment.\\n\\nStrong SQL or NoSQL skills with one or more open source DBMS such as MySql, MongoDB, Cassandra.\\n\\nExpertise in containerized environments on private or public clouds - Aws Azure, etc.\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Temporary/Contractual\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\ndeep learningKibanatensorflowdata scienceKafkakerasSparkMachine Learning',\n",
       " 'Job description\\nDear Candidate,\\n\\nWarm greetings from SP Staffing Services.\\n\\nWe are hiring Data Science / ML Resources for our Client.\\n\\nRole: Sr. Data Scientist - Machine Learning\\nExp: 10 to 15 yrs\\nLocation: Pune, Bangalore, Chennai\\n\\nRequisite:\\n\\nIdeal Resource should have 10+ years of experience in Data Science Machine Learning.\\n\\nResponsibilities:\\n\\nDesign and Develop ML / NLP models for the project requirement\\nDeliver ownership to setup ML / NLP models with respect to tools, data and infrastructure as required\\nWork closely with Product Owner and Product architect right from ML based solution conceptualization till implementation in response to a client requirement\\nThought leadership on building ML/NLP based solution based on client requirements\\nLead the ML / NLP dialogue during the customer visits and other partner events\\n\\nRequired Skills:\\n\\nStrong knowledge of Machine Learning / NLP algorithms Information extraction, named entity recognition, text clustering, Knowledge Graph, text summarization, intent classification, word embeddings, vector space models\\nStrong experience in NLP using Python\\nExperience in developing Microservices and web services\\nUnderstanding of data and data analysis, manage Large Data Sets\\nSound exposure on Pandas, Scikit and Numpy\\nMin 4+ years of experience implementing and deploying machine learning and deep learning frameworks (Spark, TensorFlow, Keras, Caffe, etc.)\\nApplication programming in cloud platforms including Azure, IBM, AWS and GCP\\nHands on experience Data Science / Big Data technology and architecture\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Computers\\nKey Skills\\nMachine LearningData SciencePython\\nTensorflowDeep LearningNumpyMicroservicesNLPGCPPandasInformation ExtractionData AnalysisKerasCaffeScikit\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " '--',\n",
       " '--',\n",
       " '--']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping job description from each url \n",
    "d=[]\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_d=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        d.append(job_d.text)\n",
    "    except:\n",
    "        d.append(\"--\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nUse predictive modeling to in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nResponsibilities include:\\nDe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\n  Skills\\nRequired Skills: Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (Python &amp; SQL)</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Job description\\nRequired Technical and Profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Scientist / Statistical Analyst</td>\n",
       "      <td>ManpowerGroup Services India Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nDepartment- BIRS (Business In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                           Lead Data Scientist BFSI   \n",
       "1                           Associate Data Scientist   \n",
       "2                 Data Scientist: Advanced Analytics   \n",
       "3                              Senior Data Scientist   \n",
       "4                              SENIOR DATA SCIENTIST   \n",
       "5                      Data Scientist (Python & SQL)   \n",
       "6    Hiring For Data Scientist / Statistical Analyst   \n",
       "7                                  Sr Data Scientist   \n",
       "8                                  Sr Data Scientist   \n",
       "9  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "\n",
       "                                        Company Experience  \\\n",
       "0                        IBM India Pvt. Limited    5-9 Yrs   \n",
       "1                         Philips India Limited    3-5 Yrs   \n",
       "2                        IBM India Pvt. Limited    3-7 Yrs   \n",
       "3                                        Airbnb   7-12 Yrs   \n",
       "4           Happiest Minds Technologies Pvt.Ltd   5-10 Yrs   \n",
       "5                                  AVE-Promagne    6-8 Yrs   \n",
       "6  ManpowerGroup Services India Private Limited    2-4 Yrs   \n",
       "7                        IBM India Pvt. Limited    6-8 Yrs   \n",
       "8                        IBM India Pvt. Limited    6-8 Yrs   \n",
       "9                  Wrackle Technologies Pvt Ltd   6-11 Yrs   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bengaluru/Bangalore   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bengaluru/Bangalore   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bengaluru/Bangalore   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                     Job_description  \n",
       "0                                                 --  \n",
       "1  Job description\\nUse predictive modeling to in...  \n",
       "2                                                 --  \n",
       "3  Job description\\nResponsibilities include:\\nDe...  \n",
       "4  Job description\\n  Skills\\nRequired Skills: Da...  \n",
       "5  Job description\\nRequired Technical and Profes...  \n",
       "6  Job description\\nDepartment- BIRS (Business In...  \n",
       "7                                                 --  \n",
       "8                                                 --  \n",
       "9  Job description\\nRoles and Responsibilities\\nR...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data frame \n",
    "data=list(zip(T,Com,EX,L,d))\n",
    "j=pd.DataFrame(data=data,columns=[\"Job_title\",\"Company\",\"Experience\",\"Location\",\"Job_description\"])\n",
    "j=j[0:10]\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-3 In this question you have to scrape data using the filters available on the\n",
    "webpage \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=driver.find_element_by_xpath(\"//input[@id='qsb-keyword-sugg']\")\n",
    "s.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "sea.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter location = Delhi\n",
    "f_l=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for i in f_l:\n",
    "    if i.text==\"Delhi / NCR\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter 3-6L\n",
    "f=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for i in f:\n",
    "    if i.text==\"3-6 Lakhs\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst/Data Scientist',\n",
       " 'Data Scientist/ Machine Learning Engineer',\n",
       " 'Data Scientist - WFH - MIND Infotech',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Data Analyst / Business Analytics - MNC Jobs Freshers',\n",
       " 'Data Scientist',\n",
       " 'Immediate Openings For Data Scientist For Wipro C2H',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist-immediate Joiners',\n",
       " 'Data Scientist - Machine Learning/ NLP',\n",
       " 'Junior Data Scientists & Engineers',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Hiring Data Scientist Develope || IDS Infotech LTD || (Permanent WFH)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist Internship',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping job title\n",
    "j_t=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "Job_T=[]\n",
    "for i in j_t:\n",
    "    Job_T.append(i.text)\n",
    "Job_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahmedabad, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram\\n(WFH during Covid)',\n",
       " 'Noida, New Delhi, Gurgaon/Gurugram',\n",
       " 'Noida\\n(WFH during Covid)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Delhi / NCR(Okhla)',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'New Delhi, Delhi / NCR',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Chandigarh, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Gurgaon, Bengaluru',\n",
       " 'Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpur, Ghaziabad, Jaunpur, Kanpur, Delhi, Lucknow, Agra, Gurgaon, Rajkot, Bengaluru',\n",
       " 'New Delhi',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping job location\n",
    "j_l=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "Lo=[]\n",
    "for i in j_l:\n",
    "    Lo.append(i.text)\n",
    "Lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skillenable Fintech Private Limited',\n",
       " 'Creative Hands HR Consultancy',\n",
       " 'MOTHERSONSUMI INFOTECH & DESIGNS LIMITED',\n",
       " 'GABA Consultancy services',\n",
       " 'CARS24',\n",
       " 'PROCESS NINE TECHNOLOGIES PVT.LTD.',\n",
       " 'GABA Consultancy services',\n",
       " 'R Systems International Ltd.',\n",
       " 'IDESLABS PRIVATE LIMITED',\n",
       " 'Kusum Healthcare Pvt. Ltd.',\n",
       " 'Quikruit Consulting LLP',\n",
       " 'TalPro',\n",
       " 'PY Consultancy',\n",
       " 'Fractal Analytics',\n",
       " 'inVentiv International Pharma Services Pvt. Ltd.',\n",
       " 'IDS Infotech Ltd.',\n",
       " 'BlackBuck',\n",
       " 'Country Veggie',\n",
       " 'iHackers Inc',\n",
       " 'UrbanClap']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping company\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "C=[]\n",
    "for i in comp:\n",
    "    C.append(i.text)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-5 Yrs',\n",
       " '0-0 Yrs',\n",
       " '3-7 Yrs',\n",
       " '0-0 Yrs',\n",
       " '1-5 Yrs',\n",
       " '1-3 Yrs',\n",
       " '0-0 Yrs',\n",
       " '3-6 Yrs',\n",
       " '5-10 Yrs',\n",
       " '4-6 Yrs',\n",
       " '2-5 Yrs',\n",
       " '2-6 Yrs',\n",
       " '0-3 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-6 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-7 Yrs',\n",
       " '1-3 Yrs',\n",
       " '0-1 Yrs',\n",
       " '1-3 Yrs']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping experience required\n",
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "E=[]\n",
    "for i in exp:\n",
    "    E.append(i.text)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(Job_T))\n",
    "print(len(C))\n",
    "print(len(E))\n",
    "print(len(Lo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst/Data Scientist</td>\n",
       "      <td>Skillenable Fintech Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/ Machine Learning Engineer</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - WFH - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PROCESS NINE TECHNOLOGIES PVT.LTD.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram\\n(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Noida\\n(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Immediate Openings For Data Scientist For Wipr...</td>\n",
       "      <td>IDESLABS PRIVATE LIMITED</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kusum Healthcare Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Delhi / NCR(Okhla)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                        Data Analyst/Data Scientist   \n",
       "1          Data Scientist/ Machine Learning Engineer   \n",
       "2               Data Scientist - WFH - MIND Infotech   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4                      Data Scientist / Data Analyst   \n",
       "5                                     Data Scientist   \n",
       "6  Data Scientist / Data Analyst / Business Analy...   \n",
       "7                                     Data Scientist   \n",
       "8  Immediate Openings For Data Scientist For Wipr...   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                    Company Experience_required  \\\n",
       "0       Skillenable Fintech Private Limited             2-5 Yrs   \n",
       "1             Creative Hands HR Consultancy             0-0 Yrs   \n",
       "2  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             3-7 Yrs   \n",
       "3                 GABA Consultancy services             0-0 Yrs   \n",
       "4                                    CARS24             1-5 Yrs   \n",
       "5        PROCESS NINE TECHNOLOGIES PVT.LTD.             1-3 Yrs   \n",
       "6                 GABA Consultancy services             0-0 Yrs   \n",
       "7              R Systems International Ltd.             3-6 Yrs   \n",
       "8                  IDESLABS PRIVATE LIMITED            5-10 Yrs   \n",
       "9                Kusum Healthcare Pvt. Ltd.             4-6 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "1  Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...  \n",
       "2  Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...  \n",
       "3               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "4                                   Gurgaon/Gurugram  \n",
       "5               Gurgaon/Gurugram\\n(WFH during Covid)  \n",
       "6                 Noida, New Delhi, Gurgaon/Gurugram  \n",
       "7                          Noida\\n(WFH during Covid)  \n",
       "8                                   Gurgaon/Gurugram  \n",
       "9                                 Delhi / NCR(Okhla)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data frame \n",
    "data=list(zip(Job_T,C,E,Lo))\n",
    "Job_n=pd.DataFrame(data=data,columns=[\"Job_title\",\"Company\",\"Experience_required\",\"Location\"])\n",
    "Job_n=Job_n[0:10]\n",
    "Job_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-4  Write a python program to scrape data for first 10 job results for Data scientist \n",
    "Designation in Noida location. You have to scrape company_name, No. of days \n",
    "ago when job was posted, Rating of the company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.glassdoor.co.in/member/home/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering data scientist into search \n",
    "jo=driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "jo.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering noida into location \n",
    "lo=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "lo.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the search button \n",
    "se=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto search__SearchStyles__newSearchButton css-1dqvyh7']\")\n",
    "se.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberin Technologies Private Limited',\n",
       " 'AlgoScale Technologies Private Limited',\n",
       " 'Lenskart',\n",
       " 'limeroad.com',\n",
       " 'Saishaa Services',\n",
       " 'Ishatva Management Solutions',\n",
       " 'Noisy Lion',\n",
       " 'Emerging India Analytics',\n",
       " 'Salasar New Age Technologies',\n",
       " 'Badatya Private Limited',\n",
       " 'Biz2Credit Inc',\n",
       " 'Techlive',\n",
       " 'Newgen Software',\n",
       " 'CaaStle',\n",
       " 'Salasar New Age Technologies',\n",
       " 'Innovacer',\n",
       " 'Bizzhype HR',\n",
       " 'Airtel India',\n",
       " 'SearchUrCollege',\n",
       " 'NEC Opportunities',\n",
       " 'Grail Insights',\n",
       " 'Gauge Data Solutions',\n",
       " 'ING',\n",
       " 'Grail Insights',\n",
       " 'Wobot.ai',\n",
       " 'NMG Technologies',\n",
       " 'Ericsson',\n",
       " 'IElevate Institute',\n",
       " 'Crowe',\n",
       " 'WinZO']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping company \n",
    "cO=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']\")\n",
    "CO=[]\n",
    "for i in cO:\n",
    "    CO.append(i.text)\n",
    "CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Analytics part time job/internship at Noida',\n",
       " 'Data Science Training Head-Full Time',\n",
       " 'Data Scientist Intern',\n",
       " 'Data Science Consultant',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Insights',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Machine Learning Engineer',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Spark Engg / Dot data',\n",
       " 'Analyst – Data Science',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Management Trainee – Data Science',\n",
       " 'Computer Vision Engineer',\n",
       " 'Urgent Opening || Python Machine Learning || NMG Technologies || Gurugram',\n",
       " 'Data Scientist',\n",
       " 'Data Science Trainer',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping job title\n",
    "Jo=driver.find_elements_by_xpath(\"//a[@class='jobLink job-search-key-1rd3saf eigr9kq1']\")\n",
    "j=[]\n",
    "for i in Jo:\n",
    "    j.append(i.text)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida',\n",
       " 'Noida',\n",
       " 'Farīdābād',\n",
       " 'Gurgaon',\n",
       " 'New Delhi',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Ghaziabad',\n",
       " 'Gurgaon',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Gurgaon',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'New Delhi']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape location \n",
    "Lo=driver.find_elements_by_xpath(\"//span[@class='css-1buaf54 pr-xxsm job-search-key-iii9i8 e1rrn5ka4']\")\n",
    "L=[]\n",
    "for i in Lo:\n",
    "    L.append(i.text)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30d+',\n",
       " '14d',\n",
       " '2d',\n",
       " '14d',\n",
       " '16d',\n",
       " '9d',\n",
       " '24h',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '11d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '24h',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '1d',\n",
       " '20d',\n",
       " '30d+',\n",
       " '21d',\n",
       " '24h',\n",
       " '30d+',\n",
       " '5d',\n",
       " '24h',\n",
       " '12d',\n",
       " '26d',\n",
       " '7d',\n",
       " '8d',\n",
       " '30d+',\n",
       " '30d+']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping \"who many days ago the listing was posted\"\n",
    "age=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")\n",
    "A=[]\n",
    "for i in age:\n",
    "    A.append(i.text)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " '--',\n",
       " '3.6 ★',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '3.9 ★',\n",
       " '--',\n",
       " '--',\n",
       " '4.5 ★',\n",
       " '4.2 ★',\n",
       " '--',\n",
       " '3.3 ★',\n",
       " '3.2 ★',\n",
       " '--',\n",
       " '3.8 ★',\n",
       " '--',\n",
       " '3.8 ★',\n",
       " '--',\n",
       " '--',\n",
       " '3.5 ★',\n",
       " '--',\n",
       " '4.0 ★',\n",
       " '3.5 ★',\n",
       " '--',\n",
       " '3.4 ★',\n",
       " '4.1 ★',\n",
       " '--',\n",
       " '3.8 ★',\n",
       " '4.0 ★']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the rating \n",
    "url=[]\n",
    "R=[]\n",
    "for i in Jo:\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "url\n",
    "\n",
    "for j in url:\n",
    "    driver.get(j)\n",
    "    try:\n",
    "        r=driver.find_element_by_xpath(\"//span[@class='css-1pmc6te e11nt52q4']\")\n",
    "        R.append(r.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        R.append(\"--\")\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Posted_on</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>h</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>t</td>\n",
       "      <td>Noida</td>\n",
       "      <td>14d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenskart</td>\n",
       "      <td>t</td>\n",
       "      <td>Farīdābād</td>\n",
       "      <td>2d</td>\n",
       "      <td>3.6 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limeroad.com</td>\n",
       "      <td>p</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>14d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saishaa Services</td>\n",
       "      <td>s</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>16d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ishatva Management Solutions</td>\n",
       "      <td>:</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>9d</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Noisy Lion</td>\n",
       "      <td>/</td>\n",
       "      <td>Noida</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.9 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Emerging India Analytics</td>\n",
       "      <td>/</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>w</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Badatya Private Limited</td>\n",
       "      <td>w</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>11d</td>\n",
       "      <td>4.5 ★</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Company Job_title   Location Posted_on  \\\n",
       "0    Liberin Technologies Private Limited         h      Noida      30d+   \n",
       "1  AlgoScale Technologies Private Limited         t      Noida       14d   \n",
       "2                                Lenskart         t  Farīdābād        2d   \n",
       "3                            limeroad.com         p    Gurgaon       14d   \n",
       "4                        Saishaa Services         s  New Delhi       16d   \n",
       "5            Ishatva Management Solutions         :  New Delhi        9d   \n",
       "6                              Noisy Lion         /      Noida       24h   \n",
       "7                Emerging India Analytics         /      Noida      30d+   \n",
       "8            Salasar New Age Technologies         w      Noida      30d+   \n",
       "9                 Badatya Private Limited         w  New Delhi       11d   \n",
       "\n",
       "  Rating  \n",
       "0     --  \n",
       "1     --  \n",
       "2  3.6 ★  \n",
       "3     --  \n",
       "4     --  \n",
       "5     --  \n",
       "6  3.9 ★  \n",
       "7     --  \n",
       "8     --  \n",
       "9  4.5 ★  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe \n",
    "data=list(zip(CO,j,L,A,R))\n",
    "Job=pd.DataFrame(data=data,columns=[\"Company\",\"Job_title\",\"Location\",\"Posted_on\",\"Rating\"])\n",
    "Job=Job[0:10]\n",
    "Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-5 Write a python program to scrape the salary data for Data Scientist designation \n",
    "in Noida location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering data scientist into search \n",
    "s=driver.find_element_by_xpath(\"//input[@id='KeywordSearch']\")\n",
    "s.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering noida into location \n",
    "l=driver.find_element_by_xpath(\"//input[@id='LocationSearch']\")\n",
    "l.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on search \n",
    "k=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "k.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services',\n",
       " 'IBM',\n",
       " 'Accenture',\n",
       " 'Delhivery',\n",
       " 'Ericsson-Worldwide',\n",
       " 'UnitedHealth Group',\n",
       " 'Optum',\n",
       " 'Optum Global Solutions',\n",
       " 'Valiance Solutions',\n",
       " 'EXL Service',\n",
       " 'Cognizant Technology Solutions',\n",
       " 'ZS Associates',\n",
       " 'Nagarro',\n",
       " 'Innovaccer',\n",
       " 'OYO',\n",
       " 'dunnhumby',\n",
       " 'Amazon',\n",
       " 'CARS24.com',\n",
       " 'Vidooly Media Tech',\n",
       " 'ParallelDots']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping company \n",
    "com=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "C=[]\n",
    "for i in com:\n",
    "    C.append(i.text)\n",
    "C\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹6,19,349 /yr',\n",
       " '₹9,00,000 /yr',\n",
       " '₹11,71,012 /yr',\n",
       " '₹12,26,283 /yr',\n",
       " '₹7,44,116 /yr',\n",
       " '₹12,80,000 /yr',\n",
       " '₹13,29,677 /yr',\n",
       " '₹14,28,139 /yr',\n",
       " '₹8,69,449 /yr',\n",
       " '₹11,10,000 /yr',\n",
       " '₹9,53,560 /yr',\n",
       " '₹11,49,894 /yr',\n",
       " '₹10,81,155 /yr',\n",
       " '₹12,17,018 /yr',\n",
       " '₹14,24,677 /yr',\n",
       " '₹11,09,179 /yr',\n",
       " '₹20,25,084 /yr',\n",
       " '₹10,60,462 /yr',\n",
       " '₹34,383 /mo',\n",
       " '₹8,32,315 /yr']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping avg salary \n",
    "avg=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "A=[]\n",
    "for i in avg:\n",
    "    A.append(i.text. replace(\"\\n\",\"\"))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9',\n",
       " '3.9',\n",
       " '4.1',\n",
       " '3.8',\n",
       " '4',\n",
       " '3.7',\n",
       " '3.7',\n",
       " '3.9',\n",
       " '4.2',\n",
       " '3.6',\n",
       " '3.8',\n",
       " '4',\n",
       " '4',\n",
       " '3.8',\n",
       " '3.3',\n",
       " '4.1',\n",
       " '3.8',\n",
       " '4.1',\n",
       " '3.8',\n",
       " '3.8']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scarping rating\n",
    "rating=driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "R=[]\n",
    "for i in rating:\n",
    "    R.append(i.text)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping maximum and minimum salary  \n",
    "min_s=[]\n",
    "max_s=[]\n",
    "url=[]\n",
    "for i in com:\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "for j in url:\n",
    "    driver.get(j)\n",
    "    try:\n",
    "        mi=driver.find_element_by_xpath(\"//div[@class='d-flex my-xxsm css-79elbk e86zor80']//strong[1]\")\n",
    "        min_s.append(mi.text)\n",
    "        ma=driver.find_element_by_xpath(\"//div[@class='d-flex my-xxsm css-79elbk e86zor80']//strong[2]\")\n",
    "        max_s.append(ma.text)\n",
    "    except:\n",
    "        print(\"--\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Minimum_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹6,19,349 /yr</td>\n",
       "      <td>3.9</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹9,00,000 /yr</td>\n",
       "      <td>3.9</td>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹11,71,012 /yr</td>\n",
       "      <td>4.1</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹12,26,283 /yr</td>\n",
       "      <td>3.8</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹7,44,116 /yr</td>\n",
       "      <td>4</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹12,80,000 /yr</td>\n",
       "      <td>3.7</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum</td>\n",
       "      <td>₹13,29,677 /yr</td>\n",
       "      <td>3.7</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹14,28,139 /yr</td>\n",
       "      <td>3.9</td>\n",
       "      <td>₹10L</td>\n",
       "      <td>₹17L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹8,69,449 /yr</td>\n",
       "      <td>4.2</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹11,10,000 /yr</td>\n",
       "      <td>3.6</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company  Average_salary Rating Minimum_salary  \\\n",
       "0  Tata Consultancy Services   ₹6,19,349 /yr    3.9            ₹4L   \n",
       "1                        IBM   ₹9,00,000 /yr    3.9            ₹1L   \n",
       "2                  Accenture  ₹11,71,012 /yr    4.1            ₹6L   \n",
       "3                  Delhivery  ₹12,26,283 /yr    3.8            ₹5L   \n",
       "4         Ericsson-Worldwide   ₹7,44,116 /yr      4            ₹4L   \n",
       "5         UnitedHealth Group  ₹12,80,000 /yr    3.7            ₹8L   \n",
       "6                      Optum  ₹13,29,677 /yr    3.7            ₹8L   \n",
       "7     Optum Global Solutions  ₹14,28,139 /yr    3.9           ₹10L   \n",
       "8         Valiance Solutions   ₹8,69,449 /yr    4.2            ₹5L   \n",
       "9                EXL Service  ₹11,10,000 /yr    3.6            ₹6L   \n",
       "\n",
       "  Maximum_salary  \n",
       "0           ₹13L  \n",
       "1           ₹28L  \n",
       "2           ₹22L  \n",
       "3           ₹1Cr  \n",
       "4           ₹16L  \n",
       "5           ₹15L  \n",
       "6           ₹20L  \n",
       "7           ₹17L  \n",
       "8           ₹15L  \n",
       "9           ₹15L  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe \n",
    "data=list(zip(C,A,R,min_s,max_s))\n",
    "J=pd.DataFrame(data=data,columns=[\"Company\",\"Average_salary\",\"Rating\",\"Minimum_salary\",\"Maximum_salary\"])\n",
    "J=J[0:10]\n",
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q - 6 Scrape data of first 100 sunglasses listings on flipkart.com. You have to \n",
    "scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "s.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search botton \n",
    "k=driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "k.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "page=0\n",
    "brand=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "dis=[]\n",
    "while page <3:\n",
    "    sleep(5) #putting the code t sleep for 5sec \n",
    "    #scrape brand names\n",
    "    b=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in b:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    #scrape description \n",
    "    d=driver.find_elements_by_class_name(\"IRpwTa\")\n",
    "    for i in d:\n",
    "        desc.append(i.text)\n",
    "    \n",
    "    #scrape price\n",
    "    p=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")[0:40]\n",
    "    for i in p:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    \n",
    "    #scrape discount \n",
    "    di=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in di:\n",
    "        dis.append(i.text)\n",
    "    \n",
    "    \n",
    "    page=page+1 #page increment \n",
    "    \n",
    "    #click on the next button\n",
    "    Next=driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[@class='_1LKTO3']/span[text()='Next']\")\n",
    "    Next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elegante</td>\n",
       "      <td>Mirrored Round Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (58)</td>\n",
       "      <td>₹854</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹329</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Aviator Sunglasses (60)</td>\n",
       "      <td>₹711</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (57)</td>\n",
       "      <td>₹503</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (58)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Butterfly Sunglasses (65)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Cat-eye Sunglasses (60)</td>\n",
       "      <td>₹745</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price  \\\n",
       "0         elegante              Mirrored Round Sunglasses (Free Size)  ₹399   \n",
       "1        ROYAL SON             Polarized Retro Square Sunglasses (58)  ₹854   \n",
       "2           PIRASO              UV Protection Aviator Sunglasses (54)  ₹237   \n",
       "3        Elligator                UV Protection Round Sunglasses (54)  ₹329   \n",
       "4   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹284   \n",
       "..             ...                                                ...   ...   \n",
       "95       ROYAL SON   UV Protection, Polarized Aviator Sunglasses (60)  ₹711   \n",
       "96        Fastrack             UV Protection Wayfarer Sunglasses (57)  ₹503   \n",
       "97       ROYAL SON         UV Protection Retro Square Sunglasses (58)  ₹474   \n",
       "98          PIRASO            UV Protection Butterfly Sunglasses (65)  ₹449   \n",
       "99          AISLIN    UV Protection, Gradient Cat-eye Sunglasses (60)  ₹745   \n",
       "\n",
       "   Discount  \n",
       "0   80% off  \n",
       "1   57% off  \n",
       "2   85% off  \n",
       "3   86% off  \n",
       "4   89% off  \n",
       "..      ...  \n",
       "95  64% off  \n",
       "96  37% off  \n",
       "97  68% off  \n",
       "98  82% off  \n",
       "99  76% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe\n",
    "data=list(zip(brand,desc,price,dis))\n",
    "glass=pd.DataFrame(data=data,columns=[\"Brand\",\"Description\",\"Price\",\"Discount\"])\n",
    "glass=glass[0:100]\n",
    "glass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q - 7  Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes%02earpods-power%02adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get all the reviews \n",
    "c=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']/span\")\n",
    "c.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "short=[]\n",
    "review=[]\n",
    "page=0\n",
    "\n",
    "while page<11:\n",
    "    sleep(5) #putting the code to sleep for 5seconds \n",
    "    \n",
    "    #scraping rating\n",
    "    r=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in r:\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    #scraping short description \n",
    "    s=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for i in s:\n",
    "        short.append(i.text)\n",
    "     \n",
    "    \n",
    "    #scraping full review \n",
    "    r=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for i in r:\n",
    "        review.append(i.text)\n",
    "        \n",
    "    \n",
    "    page=page+1 #increment \n",
    "    \n",
    "    #clicking the next button\n",
    "    n=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "    n.click()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5    Worth every penny   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                          Full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  i11 is worthy to buy, too much happy with the ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data frame \n",
    "data=list(zip(rating,short,review))\n",
    "phone=pd.DataFrame(data=data,columns=[\"Rating\",\"Review_summary\",\"Full_review\"])\n",
    "phone=phone[0:100]\n",
    "phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Q - 8 Scrape data for first 100 sneakers you find when you visit flipkart.com and \n",
    "search for “sneakers” in the search field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering sneakers into search  \n",
    "s=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "s.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button \n",
    "k=driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "k.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM439G Sneakers For Men</td>\n",
       "      <td>₹649</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Hip Hop Mid Perf IDP Sneakers For Men</td>\n",
       "      <td>₹1,535</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-482 Sneakers For Men</td>\n",
       "      <td>₹999</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹567</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SD-323 Sneakers For Men</td>\n",
       "      <td>₹625</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Bari Sneakers For Men</td>\n",
       "      <td>₹1,016</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-282 Sneakers For Men</td>\n",
       "      <td>₹899</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹498</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description   Price  \\\n",
       "0            SPARX                            SM439G Sneakers For Men    ₹649   \n",
       "1             PUMA              Hip Hop Mid Perf IDP Sneakers For Men  ₹1,535   \n",
       "2            SPARX                            SM-482 Sneakers For Men    ₹999   \n",
       "3           Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹567   \n",
       "4   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...    ₹379   \n",
       "..             ...                                                ...     ...   \n",
       "95           SPARX                            SD-323 Sneakers For Men    ₹625   \n",
       "96            PUMA                              Bari Sneakers For Men  ₹1,016   \n",
       "97           SPARX                            SM-282 Sneakers For Men    ₹899   \n",
       "98          Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...    ₹498   \n",
       "99         Numenzo                                   Sneakers For Men    ₹449   \n",
       "\n",
       "   Discount  \n",
       "0    7% off  \n",
       "1   56% off  \n",
       "2   21% off  \n",
       "3   64% off  \n",
       "4   70% off  \n",
       "..      ...  \n",
       "95  16% off  \n",
       "96  66% off  \n",
       "97  25% off  \n",
       "98  72% off  \n",
       "99  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import sleep\n",
    "page=0\n",
    "brand=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "dis=[]\n",
    "\n",
    "while page<3:\n",
    "    sleep(5)\n",
    "    \n",
    "    #scraping brand names \n",
    "    b=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in b:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    #scraping product description\n",
    "    d=driver.find_elements_by_class_name(\"IRpwTa\")\n",
    "    for i in d:\n",
    "        desc.append(i.text)\n",
    "        \n",
    "    #scraping price \n",
    "    p=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in p:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    #scraping discounts\n",
    "    di=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in di:\n",
    "        dis.append(i.text)\n",
    "    \n",
    "    page=page+1 #increment \n",
    "    \n",
    "    #cicking the next button \n",
    "    nex=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "    nex.click()\n",
    "    \n",
    "    \n",
    "#dataframe \n",
    "data=list(zip(brand,desc,price,dis))\n",
    "sneakers=pd.DataFrame(data=data,columns=[\"Brand\",\"Description\",\"Price\",\"Discount\"])\n",
    "sneakers= sneakers[0:100]\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q - 9 Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying colour filter \n",
    "sleep(5)\n",
    "f_c=driver.find_elements_by_xpath(\"//li[@class='colour-listItem']/label[@class='common-customCheckbox']\")[0]\n",
    "f_c.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying price filter \n",
    "f_p=driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox vertical-filters-label']\")\n",
    "for i in f_p:\n",
    "    if i.text==\"Rs. 6935 to Rs. 13621(696)\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Air Zoom Structure Running</td>\n",
       "      <td>Rs. 10295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Velocity Nitro Running</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Mesh Hybrid Fuego Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Oxfords</td>\n",
       "      <td>Rs. 8094Rs. 13490(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 11242Rs. 14990(25% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand               Product_description                        Price\n",
       "0        Nike    Men Air Zoom Structure Running                    Rs. 10295\n",
       "1        ALDO                 Men Driving Shoes                    Rs. 11999\n",
       "2        Puma    Men Cell Fraction Fade Running                     Rs. 6999\n",
       "3        Puma        Men Velocity Nitro Running                    Rs. 10999\n",
       "4        Puma         Mesh Hybrid Fuego Running                     Rs. 6999\n",
       "..        ...                               ...                          ...\n",
       "95    Saint G        Women Leather Heeled Boots                     Rs. 8900\n",
       "96    Saint G        Women Leather Heeled Boots                     Rs. 7600\n",
       "97      Ruosh  Men Solid Leather Formal Oxfords   Rs. 8094Rs. 13490(40% OFF)\n",
       "98  J.FONTINI      Men Textured Leather Loafers                     Rs. 6990\n",
       "99       Geox       Men Leather Formal Slip-Ons  Rs. 11242Rs. 14990(25% OFF)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=0\n",
    "brand=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "\n",
    "while page<2:\n",
    "    sleep(5)\n",
    "    \n",
    "    #scraping brand name \n",
    "    b=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    for i in b:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    \n",
    "    #scraping product description \n",
    "    d=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    for i in d:\n",
    "        desc.append(i.text)\n",
    "    \n",
    "    \n",
    "    #scraping price \n",
    "    p=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for i in p:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    page=page+1 #increment \n",
    "    \n",
    "    n=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "    n.click()\n",
    "    \n",
    "    \n",
    "#dataframe\n",
    "data=list(zip(brand,desc,price))\n",
    "shoe=pd.DataFrame(data=data,columns=[\"Brand\",\"Product_description\",\"Price\"])\n",
    "shoe=shoe[0:100]\n",
    "shoe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q - 10 Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=driver.find_element_by_xpath(\"//input[@id='twotabsearchtextbox']\")\n",
    "s.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "k.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter Intel Core i7\n",
    "f_7=driver.find_element_by_xpath(\"//li[@id='p_n_feature_thirteen_browse-bin/12598163031']/span\")\n",
    "f_7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter intel core i9\n",
    "f_9=driver.find_element_by_xpath(\"//li[@id='p_n_feature_thirteen_browse-bin/16757432031']/span\")\n",
    "f_9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dell XPS 9370 13.3-inch FHD Display Thin & Light Laptop (8th Gen i7-8550U/16GB/512GB SSD/Win 10 + MS Office/Integrated Graphics), Gold',\n",
       " 'HP Envy 11th Gen Core i7 Processor 13.3-inch (33.78 cms) FHD Touchscreen Laptop (16GB/1TB SSD/Win 10/NVIDIA MX450 2GB/Natural Silver/1.3 kg), 13-ba1018TX',\n",
       " 'Lenovo IdeaPad S540 11th Gen Intel Core i7 13.3\" QHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Intel Iris Xe Graphics/Iron Grey/1.28Kg), 82H1002CIN',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg)(Without Webcam) XMA1904-AF',\n",
       " 'ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms) FHD 144Hz, Intel Core i7-11370H 11th Gen, RTX 3050 4GB Graphics Gaming Laptop (16GB RAM/512GB SSD/Windows 10/Gray/2 kg), FX516PC-HN063T',\n",
       " 'ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 cms) FHD 144Hz, Intel Core i7-11800H 11th Gen, GeForce RTX 3050 Ti 4GB Graphics, Gaming Laptop (16GB/1TB SSD/Windows 10/Eclipse Gray/2.6 Kg) FX766HE-HX022T',\n",
       " 'ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 144Hz/3ms Gaming Laptop (8th Gen Intel Core i9-8950HK/64GB/2TB SSHD + 1.5TB NVMe SSD/Windows 10/GTX 1080 8GB Graphics/4.70 Kg), Aluminum',\n",
       " 'Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen 15.6\" FHD IPS 250Nits Gaming Laptop (8GB/512GB SSD/Win10/NVIDIA GTX 1650 4GB GDDR6 Graphics/120Hz/Onyx Black/2.2Kg), 81Y4019EIN',\n",
       " 'HP Pavilion 13(2021) 11th Gen Intel Core i7 Laptop, 16GB RAM, 1TB SSD, 13.3-inch(33.8 cm) FHD Screen, Win 10, MS Office, Ceramic White, 1.24 Kg (13-bb0078TU)',\n",
       " 'MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm) FHD IPS-Level 144Hz Panel Laptop (8GB/512GB NVMe SSD/Windows 10 Home/Nvidia GTX1650 4GB GDDR6/Black/2.2Kg), 10SCXR-654IN',\n",
       " 'Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33.78cm) FHD IPS 400Nits 2-in1 Touch Convertible Laptop (16GB/1TB SSD/Win10/Office/Iris Xe Graphics/Backlit Kb/Black/997gms), 4ZR1D71993',\n",
       " 'Mi Notebook Pro QHD+ IPS Anti Glare Display Intel Core i7-11370H 11th Gen 14-inch(35.56 cms) Thin and Light Laptop (16GB/512GB SSD/Iris Xe Graphics/Win 10/Backlit KB/Fingerprint Sensor/1.4 Kg)',\n",
       " 'Acer Nitro 5 Core i7 11th Gen 15.6\" (39.62cms) Full HD IPS Gaming Laptop (16 GB/256GB SSD/1 TB HDD/Win 10/4 GB Graphics/NVIDIA GeForce RTX 3050 Ti/144 Hz, Black, 2.4 kg) AN515-57',\n",
       " 'ASUS TUF Dash F15 (2021) 15.6\" (39.62 cm) FHD 240Hz/3ms, Intel Core i7-11370H, GeForce RTX 3060 6GB Graphics, Gaming Laptop (16GB RAM/1TB SSD/Office 2019/Windows 10 Home/Gray/2 Kg) FX516PM-AZ153TS',\n",
       " 'Acer Swift 5 14\" (35.56cms) Full HD IPS Display with Touchscreen Ultra Thin and Light Notebook (Intel i7 - 11th Gen/16GB RAM/1TB SSD/Win10/Intel Iris Xe Graphics/1.05 Kg/Mist Green), SF514-55TA',\n",
       " '(Renewed) Hp Intel 4th Gen Core i7 15.6-inch (39.56 Cms) 1920 x 1080 Laptop (32GB RAM /1TB SSD/Windows 10 Pro/MS Office/NVIDIA Graphics/ Gray/2.5kg) HP ZBook 15 Mobile Workstation',\n",
       " '(Renewed) Hp Intel 7th Gen Core i7 13.3-inch (33.78 Cms) 1920 x 1080 TOUCHSCREEN Laptop (16GB RAM/1TB SSD/Windows 10 Pro/MS Office/Intel HD Integrated Graphics/ Silver/1.2Kg) EliteBook x360 G2',\n",
       " 'Mi Notebook Ultra 3K Resolution Display Intel Core i7-11370H 11th Gen 15.6-inch(39.62 cms) Thin and Light Laptop (16GB/512GB SSD/Iris Xe Graphics/Win 10/MS Office/Backlit KB/Fingerprint Sensor/1.7Kg)',\n",
       " 'ASUS VivoBook S S15 (2021), 15.6-inch (39.62 cms) FHD Intel Core i7-1165G7 11th Gen, Thin and Light Laptop (8GB/512GB SSD/Office 2019/Windows 10/2GB NVIDIA MX350 Graphics/Silver/1.8 kg) S532EQ-BQ702TS',\n",
       " 'ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 cms) FHD 144Hz, Intel Core i7-11800H 11th Gen, GeForce RTX 3050 4GB Graphics, Gaming Laptop (8GB/512GB SSD/Windows 10/Eclipse Gray/2.3 Kg), FX566HC-HN093T',\n",
       " 'Lenovo Yoga 7 11th Gen Intel Core i7 14\" Full HD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Lenovo Digital Pen/Slate Grey/Aluminium Surface/1.43Kg), 82BH00E0IN',\n",
       " 'Acer Nitro 5 Intel Core i7-11th Gen 15.6-inch (39.62 cms) 144 Hz Refresh Rate Gaming Laptop (8GB RAM/RTX 3050 Graphics/1TB HDD + 256GB SSD/Windows 10 HS/Black/2.4 Kgs), AN515-57',\n",
       " 'Fujitsu UH-X 11th Gen Intel i7 Core 13.3” (33.78cm) FHD IPS 400Nits Thin and Light Laptop (16GB/512GB SSD/Win10/Office/Iris Xe Graphics/Backlit Kb/ Fingerprint Reader/Black/878gms), 4ZR1D67596',\n",
       " 'HP Pavilion Gaming 11th Gen Intel Core i7 15.6-inch(39.6 cm) FHD Gaming Laptop (16GB RAM/512GB SSD/144Hz/GTX 1650 4GB Graphics/Win 10/MS Office/Shadow Black/2.28 Kg), 15-dk2075tx',\n",
       " '(Renewed) HP Pavilion Gaming(2021) 10th Gen Intel Core i7 15.6-inch(39.6 cm) FHD IPS 144Hz Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/NVIDIA GTX 1650Ti 4GB/Win 10/MS Office/Shadow Black), 15-DK1511TX',\n",
       " 'ASUS VivoBook S S14 Intel Core i7-1165G7 11th Gen, 14-inch FHD Thin and Light Laptop (8GB RAM/512GB SSD + 32GB Optane Memory/Windows 10/Office 2019/Iris X Graphics- Indie Black/1.4 Kg), S433EA-AM701TS',\n",
       " 'Lenovo Yoga Slim 7 Carbon 11th Gen Intel Core i7 13.3\" (33.78cm) QHD IPS Ultra-Light & Thin Laptop (16GB/1TB SSD/Windows 10/MS Office/Intel Iris Xe GFX/Carbon Fiber/Moon White/0.96 Kg), 82EV003WIN']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping title\n",
    "t=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "title=[]\n",
    "for i in t:\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=[]\n",
    "price=[]\n",
    "rating=[]\n",
    "u=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']//a\")\n",
    "#scrape url \n",
    "for i in u:\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    #scraping price of each laptop \n",
    "    try:\n",
    "        p=driver.find_element_by_xpath(\"//tr[@id='priceblock_ourprice_row']//td[2]\")\n",
    "        price.append(p.text)\n",
    "    except:\n",
    "        price.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping rating\n",
    "for i in url[0:10]:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        r=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        rating.append(r.text)\n",
    "    except:\n",
    "        rating.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop_title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell XPS 9370 13.3-inch FHD Display Thin &amp; Lig...</td>\n",
       "      <td>₹1,14,990.00</td>\n",
       "      <td>2.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>₹1,23,300.00</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>₹77,990.00</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>₹57,990.00</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>₹87,990.00</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td>₹1,13,990.00</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>₹5,56,524.00</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>₹73,990.00</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td>₹94,500.00</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...</td>\n",
       "      <td>₹74,990.00</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop_title         Price  \\\n",
       "0  Dell XPS 9370 13.3-inch FHD Display Thin & Lig...  ₹1,14,990.00   \n",
       "1  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  ₹1,23,300.00   \n",
       "2  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....    ₹77,990.00   \n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...    ₹57,990.00   \n",
       "4  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...    ₹87,990.00   \n",
       "5  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...  ₹1,13,990.00   \n",
       "6  ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...  ₹5,56,524.00   \n",
       "7  Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...    ₹73,990.00   \n",
       "8  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...    ₹94,500.00   \n",
       "9  MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...    ₹74,990.00   \n",
       "\n",
       "        Ratings  \n",
       "0  2.8 out of 5  \n",
       "1  4.1 out of 5  \n",
       "2  4.3 out of 5  \n",
       "3  4.2 out of 5  \n",
       "4  3.5 out of 5  \n",
       "5            --  \n",
       "6  3.9 out of 5  \n",
       "7  4.4 out of 5  \n",
       "8    5 out of 5  \n",
       "9  4.2 out of 5  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe \n",
    "data=list(zip(title,price,rating))\n",
    "laptop=pd.DataFrame(data=data,columns=[\"Laptop_title\",\"Price\",\"Ratings\"])\n",
    "laptop=laptop[0:10]\n",
    "laptop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
